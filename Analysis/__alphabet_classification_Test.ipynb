{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1e702242",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ryoii\\anaconda3\\lib\\site-packages\\pandas\\core\\computation\\expressions.py:21: UserWarning: Pandas requires version '2.8.4' or newer of 'numexpr' (version '2.8.1' currently installed).\n",
      "  from pandas.core.computation.check import NUMEXPR_INSTALLED\n",
      "c:\\Users\\ryoii\\anaconda3\\lib\\site-packages\\pandas\\core\\arrays\\masked.py:60: UserWarning: Pandas requires version '1.3.6' or newer of 'bottleneck' (version '1.3.4' currently installed).\n",
      "  from pandas.core import (\n"
     ]
    }
   ],
   "source": [
    "# import libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import os\n",
    "import mne\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score,confusion_matrix\n",
    "import tensorflow\n",
    "from tensorflow.keras.models import Sequential, Model, load_model\n",
    "from tensorflow.keras.utils import plot_model, to_categorical\n",
    "from tensorflow.keras.layers import Dense, Activation, Conv1D, MaxPooling1D, GlobalAveragePooling1D, Flatten, Dropout, BatchNormalization, Input,UpSampling1D\n",
    "from tensorflow.keras.layers import concatenate, Lambda, Conv2D, MaxPooling2D, GlobalAveragePooling2D,LSTM\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3833cbc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated Working Directory: c:\\Users\\ryoii\\Desktop\\EEG2IMAGE\n"
     ]
    }
   ],
   "source": [
    "# set directory\n",
    "parent_dir = os.path.dirname(os.getcwd())\n",
    "\n",
    "fo = os.path.join(parent_dir, 'data', 'Envisioned_Speech_Recognition', 'Char')\n",
    "os.chdir(parent_dir)\n",
    "print(\"Updated Working Directory:\", os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "35e3f192",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __00_load_edf import load_alphabet\n",
    "from __01_transform_data import process_band, transform_eeg_data, MA_X, MA_X2, butterworth_highpass_filter, notch_filter, zscore_standardize, dwt_reconstruct, minmax_scale, apply_ica_eeg\n",
    "from __02_model import train, visualize, train_multibranch, evaluate, train_LateFusion, train_Attention_LateFusion\n",
    "from __03_utils import plot_eeg, plot_eeg_1280"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2b6f3f5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting EDF parameters from c:\\Users\\ryoii\\Desktop\\EEG2IMAGE\\data\\Envisioned_Speech_Recognition\\Char\\aashay_A.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Relevant Channels: ['AF3', 'F7', 'F3', 'FC5', 'T7', 'P7', 'O1', 'O2', 'P8', 'T8', 'FC6', 'F4', 'F8', 'AF4']\n",
      "Extracting EDF parameters from c:\\Users\\ryoii\\Desktop\\EEG2IMAGE\\data\\Envisioned_Speech_Recognition\\Char\\aashay_C.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Extracting EDF parameters from c:\\Users\\ryoii\\Desktop\\EEG2IMAGE\\data\\Envisioned_Speech_Recognition\\Char\\aashay_F.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Extracting EDF parameters from c:\\Users\\ryoii\\Desktop\\EEG2IMAGE\\data\\Envisioned_Speech_Recognition\\Char\\aashay_H.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Extracting EDF parameters from c:\\Users\\ryoii\\Desktop\\EEG2IMAGE\\data\\Envisioned_Speech_Recognition\\Char\\aashay_J.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Extracting EDF parameters from c:\\Users\\ryoii\\Desktop\\EEG2IMAGE\\data\\Envisioned_Speech_Recognition\\Char\\aashay_M.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Extracting EDF parameters from c:\\Users\\ryoii\\Desktop\\EEG2IMAGE\\data\\Envisioned_Speech_Recognition\\Char\\aashay_P.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Extracting EDF parameters from c:\\Users\\ryoii\\Desktop\\EEG2IMAGE\\data\\Envisioned_Speech_Recognition\\Char\\aashay_S.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Extracting EDF parameters from c:\\Users\\ryoii\\Desktop\\EEG2IMAGE\\data\\Envisioned_Speech_Recognition\\Char\\aashay_T.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Extracting EDF parameters from c:\\Users\\ryoii\\Desktop\\EEG2IMAGE\\data\\Envisioned_Speech_Recognition\\Char\\aashay_Y.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Extracting EDF parameters from c:\\Users\\ryoii\\Desktop\\EEG2IMAGE\\data\\Envisioned_Speech_Recognition\\Char\\AnkurGhartaan_A.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Extracting EDF parameters from c:\\Users\\ryoii\\Desktop\\EEG2IMAGE\\data\\Envisioned_Speech_Recognition\\Char\\AnkurGhartaan_C.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Extracting EDF parameters from c:\\Users\\ryoii\\Desktop\\EEG2IMAGE\\data\\Envisioned_Speech_Recognition\\Char\\AnkurGhartaan_F.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Extracting EDF parameters from c:\\Users\\ryoii\\Desktop\\EEG2IMAGE\\data\\Envisioned_Speech_Recognition\\Char\\AnkurGhartaan_H.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Extracting EDF parameters from c:\\Users\\ryoii\\Desktop\\EEG2IMAGE\\data\\Envisioned_Speech_Recognition\\Char\\AnkurGhartaan_J.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Extracting EDF parameters from c:\\Users\\ryoii\\Desktop\\EEG2IMAGE\\data\\Envisioned_Speech_Recognition\\Char\\AnkurGhartaan_M.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Extracting EDF parameters from c:\\Users\\ryoii\\Desktop\\EEG2IMAGE\\data\\Envisioned_Speech_Recognition\\Char\\AnkurGhartaan_P.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Extracting EDF parameters from c:\\Users\\ryoii\\Desktop\\EEG2IMAGE\\data\\Envisioned_Speech_Recognition\\Char\\AnkurGhartaan_S.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Extracting EDF parameters from c:\\Users\\ryoii\\Desktop\\EEG2IMAGE\\data\\Envisioned_Speech_Recognition\\Char\\AnkurGhartaan_T.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Extracting EDF parameters from c:\\Users\\ryoii\\Desktop\\EEG2IMAGE\\data\\Envisioned_Speech_Recognition\\Char\\AnkurGhartaan_Y.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Extracting EDF parameters from c:\\Users\\ryoii\\Desktop\\EEG2IMAGE\\data\\Envisioned_Speech_Recognition\\Char\\AshishMohan_A.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Extracting EDF parameters from c:\\Users\\ryoii\\Desktop\\EEG2IMAGE\\data\\Envisioned_Speech_Recognition\\Char\\AshishMohan_C.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Extracting EDF parameters from c:\\Users\\ryoii\\Desktop\\EEG2IMAGE\\data\\Envisioned_Speech_Recognition\\Char\\AshishMohan_F.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Extracting EDF parameters from c:\\Users\\ryoii\\Desktop\\EEG2IMAGE\\data\\Envisioned_Speech_Recognition\\Char\\AshishMohan_H.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Extracting EDF parameters from c:\\Users\\ryoii\\Desktop\\EEG2IMAGE\\data\\Envisioned_Speech_Recognition\\Char\\AshishMohan_J.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Extracting EDF parameters from c:\\Users\\ryoii\\Desktop\\EEG2IMAGE\\data\\Envisioned_Speech_Recognition\\Char\\AshishMohan_M.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Extracting EDF parameters from c:\\Users\\ryoii\\Desktop\\EEG2IMAGE\\data\\Envisioned_Speech_Recognition\\Char\\AshishMohan_P.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Extracting EDF parameters from c:\\Users\\ryoii\\Desktop\\EEG2IMAGE\\data\\Envisioned_Speech_Recognition\\Char\\AshishMohan_S.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Extracting EDF parameters from c:\\Users\\ryoii\\Desktop\\EEG2IMAGE\\data\\Envisioned_Speech_Recognition\\Char\\AshishMohan_T.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Extracting EDF parameters from c:\\Users\\ryoii\\Desktop\\EEG2IMAGE\\data\\Envisioned_Speech_Recognition\\Char\\AshishMohan_Y.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Extracting EDF parameters from c:\\Users\\ryoii\\Desktop\\EEG2IMAGE\\data\\Envisioned_Speech_Recognition\\Char\\atulraj_A.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Extracting EDF parameters from c:\\Users\\ryoii\\Desktop\\EEG2IMAGE\\data\\Envisioned_Speech_Recognition\\Char\\atulraj_C.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Extracting EDF parameters from c:\\Users\\ryoii\\Desktop\\EEG2IMAGE\\data\\Envisioned_Speech_Recognition\\Char\\atulraj_F.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Extracting EDF parameters from c:\\Users\\ryoii\\Desktop\\EEG2IMAGE\\data\\Envisioned_Speech_Recognition\\Char\\atulraj_H.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Extracting EDF parameters from c:\\Users\\ryoii\\Desktop\\EEG2IMAGE\\data\\Envisioned_Speech_Recognition\\Char\\atulraj_J.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Extracting EDF parameters from c:\\Users\\ryoii\\Desktop\\EEG2IMAGE\\data\\Envisioned_Speech_Recognition\\Char\\atulraj_M.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Extracting EDF parameters from c:\\Users\\ryoii\\Desktop\\EEG2IMAGE\\data\\Envisioned_Speech_Recognition\\Char\\atulraj_P.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Extracting EDF parameters from c:\\Users\\ryoii\\Desktop\\EEG2IMAGE\\data\\Envisioned_Speech_Recognition\\Char\\atulraj_S.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Extracting EDF parameters from c:\\Users\\ryoii\\Desktop\\EEG2IMAGE\\data\\Envisioned_Speech_Recognition\\Char\\atulraj_T.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Extracting EDF parameters from c:\\Users\\ryoii\\Desktop\\EEG2IMAGE\\data\\Envisioned_Speech_Recognition\\Char\\atulraj_Y.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Extracting EDF parameters from c:\\Users\\ryoii\\Desktop\\EEG2IMAGE\\data\\Envisioned_Speech_Recognition\\Char\\ChandanSingha_A.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Extracting EDF parameters from c:\\Users\\ryoii\\Desktop\\EEG2IMAGE\\data\\Envisioned_Speech_Recognition\\Char\\ChandanSingha_C.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Extracting EDF parameters from c:\\Users\\ryoii\\Desktop\\EEG2IMAGE\\data\\Envisioned_Speech_Recognition\\Char\\ChandanSingha_F.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Extracting EDF parameters from c:\\Users\\ryoii\\Desktop\\EEG2IMAGE\\data\\Envisioned_Speech_Recognition\\Char\\ChandanSingha_H.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Extracting EDF parameters from c:\\Users\\ryoii\\Desktop\\EEG2IMAGE\\data\\Envisioned_Speech_Recognition\\Char\\ChandanSingha_J.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Extracting EDF parameters from c:\\Users\\ryoii\\Desktop\\EEG2IMAGE\\data\\Envisioned_Speech_Recognition\\Char\\ChandanSingha_M.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Extracting EDF parameters from c:\\Users\\ryoii\\Desktop\\EEG2IMAGE\\data\\Envisioned_Speech_Recognition\\Char\\ChandanSingha_P.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Extracting EDF parameters from c:\\Users\\ryoii\\Desktop\\EEG2IMAGE\\data\\Envisioned_Speech_Recognition\\Char\\ChandanSingha_S.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Extracting EDF parameters from c:\\Users\\ryoii\\Desktop\\EEG2IMAGE\\data\\Envisioned_Speech_Recognition\\Char\\ChandanSingha_T.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Extracting EDF parameters from c:\\Users\\ryoii\\Desktop\\EEG2IMAGE\\data\\Envisioned_Speech_Recognition\\Char\\ChandanSingha_Y.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Extracting EDF parameters from c:\\Users\\ryoii\\Desktop\\EEG2IMAGE\\data\\Envisioned_Speech_Recognition\\Char\\gautam_A.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Extracting EDF parameters from c:\\Users\\ryoii\\Desktop\\EEG2IMAGE\\data\\Envisioned_Speech_Recognition\\Char\\gautam_C.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Extracting EDF parameters from c:\\Users\\ryoii\\Desktop\\EEG2IMAGE\\data\\Envisioned_Speech_Recognition\\Char\\gautam_F.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Extracting EDF parameters from c:\\Users\\ryoii\\Desktop\\EEG2IMAGE\\data\\Envisioned_Speech_Recognition\\Char\\gautam_H.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Extracting EDF parameters from c:\\Users\\ryoii\\Desktop\\EEG2IMAGE\\data\\Envisioned_Speech_Recognition\\Char\\gautam_J.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Extracting EDF parameters from c:\\Users\\ryoii\\Desktop\\EEG2IMAGE\\data\\Envisioned_Speech_Recognition\\Char\\gautam_M.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Extracting EDF parameters from c:\\Users\\ryoii\\Desktop\\EEG2IMAGE\\data\\Envisioned_Speech_Recognition\\Char\\gautam_P.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Extracting EDF parameters from c:\\Users\\ryoii\\Desktop\\EEG2IMAGE\\data\\Envisioned_Speech_Recognition\\Char\\gautam_S.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Extracting EDF parameters from c:\\Users\\ryoii\\Desktop\\EEG2IMAGE\\data\\Envisioned_Speech_Recognition\\Char\\gautam_T.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Extracting EDF parameters from c:\\Users\\ryoii\\Desktop\\EEG2IMAGE\\data\\Envisioned_Speech_Recognition\\Char\\gautam_Y.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Extracting EDF parameters from c:\\Users\\ryoii\\Desktop\\EEG2IMAGE\\data\\Envisioned_Speech_Recognition\\Char\\hemant_A.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Extracting EDF parameters from c:\\Users\\ryoii\\Desktop\\EEG2IMAGE\\data\\Envisioned_Speech_Recognition\\Char\\hemant_C.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Extracting EDF parameters from c:\\Users\\ryoii\\Desktop\\EEG2IMAGE\\data\\Envisioned_Speech_Recognition\\Char\\hemant_F.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Extracting EDF parameters from c:\\Users\\ryoii\\Desktop\\EEG2IMAGE\\data\\Envisioned_Speech_Recognition\\Char\\hemant_H.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Extracting EDF parameters from c:\\Users\\ryoii\\Desktop\\EEG2IMAGE\\data\\Envisioned_Speech_Recognition\\Char\\hemant_J.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Extracting EDF parameters from c:\\Users\\ryoii\\Desktop\\EEG2IMAGE\\data\\Envisioned_Speech_Recognition\\Char\\hemant_M.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Extracting EDF parameters from c:\\Users\\ryoii\\Desktop\\EEG2IMAGE\\data\\Envisioned_Speech_Recognition\\Char\\hemant_P.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Extracting EDF parameters from c:\\Users\\ryoii\\Desktop\\EEG2IMAGE\\data\\Envisioned_Speech_Recognition\\Char\\hemant_S.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Extracting EDF parameters from c:\\Users\\ryoii\\Desktop\\EEG2IMAGE\\data\\Envisioned_Speech_Recognition\\Char\\hemant_T.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Extracting EDF parameters from c:\\Users\\ryoii\\Desktop\\EEG2IMAGE\\data\\Envisioned_Speech_Recognition\\Char\\hemant_Y.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Extracting EDF parameters from c:\\Users\\ryoii\\Desktop\\EEG2IMAGE\\data\\Envisioned_Speech_Recognition\\Char\\kartik_A.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Extracting EDF parameters from c:\\Users\\ryoii\\Desktop\\EEG2IMAGE\\data\\Envisioned_Speech_Recognition\\Char\\kartik_C.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Extracting EDF parameters from c:\\Users\\ryoii\\Desktop\\EEG2IMAGE\\data\\Envisioned_Speech_Recognition\\Char\\kartik_F.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Extracting EDF parameters from c:\\Users\\ryoii\\Desktop\\EEG2IMAGE\\data\\Envisioned_Speech_Recognition\\Char\\kartik_H.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Extracting EDF parameters from c:\\Users\\ryoii\\Desktop\\EEG2IMAGE\\data\\Envisioned_Speech_Recognition\\Char\\kartik_J.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Extracting EDF parameters from c:\\Users\\ryoii\\Desktop\\EEG2IMAGE\\data\\Envisioned_Speech_Recognition\\Char\\kartik_M.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Extracting EDF parameters from c:\\Users\\ryoii\\Desktop\\EEG2IMAGE\\data\\Envisioned_Speech_Recognition\\Char\\kartik_P.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Extracting EDF parameters from c:\\Users\\ryoii\\Desktop\\EEG2IMAGE\\data\\Envisioned_Speech_Recognition\\Char\\kartik_S.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Extracting EDF parameters from c:\\Users\\ryoii\\Desktop\\EEG2IMAGE\\data\\Envisioned_Speech_Recognition\\Char\\kartik_T.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Extracting EDF parameters from c:\\Users\\ryoii\\Desktop\\EEG2IMAGE\\data\\Envisioned_Speech_Recognition\\Char\\kartik_Y.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Extracting EDF parameters from c:\\Users\\ryoii\\Desktop\\EEG2IMAGE\\data\\Envisioned_Speech_Recognition\\Char\\mahendra_A.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Extracting EDF parameters from c:\\Users\\ryoii\\Desktop\\EEG2IMAGE\\data\\Envisioned_Speech_Recognition\\Char\\mahendra_C.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Extracting EDF parameters from c:\\Users\\ryoii\\Desktop\\EEG2IMAGE\\data\\Envisioned_Speech_Recognition\\Char\\mahendra_F.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Extracting EDF parameters from c:\\Users\\ryoii\\Desktop\\EEG2IMAGE\\data\\Envisioned_Speech_Recognition\\Char\\mahendra_H.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Extracting EDF parameters from c:\\Users\\ryoii\\Desktop\\EEG2IMAGE\\data\\Envisioned_Speech_Recognition\\Char\\mahendra_J.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Extracting EDF parameters from c:\\Users\\ryoii\\Desktop\\EEG2IMAGE\\data\\Envisioned_Speech_Recognition\\Char\\mahendra_M.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Extracting EDF parameters from c:\\Users\\ryoii\\Desktop\\EEG2IMAGE\\data\\Envisioned_Speech_Recognition\\Char\\mahendra_P.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Extracting EDF parameters from c:\\Users\\ryoii\\Desktop\\EEG2IMAGE\\data\\Envisioned_Speech_Recognition\\Char\\mahendra_S.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Extracting EDF parameters from c:\\Users\\ryoii\\Desktop\\EEG2IMAGE\\data\\Envisioned_Speech_Recognition\\Char\\mahendra_T.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Extracting EDF parameters from c:\\Users\\ryoii\\Desktop\\EEG2IMAGE\\data\\Envisioned_Speech_Recognition\\Char\\mahendra_Y.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Extracting EDF parameters from c:\\Users\\ryoii\\Desktop\\EEG2IMAGE\\data\\Envisioned_Speech_Recognition\\Char\\Nishant_A.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Extracting EDF parameters from c:\\Users\\ryoii\\Desktop\\EEG2IMAGE\\data\\Envisioned_Speech_Recognition\\Char\\Nishant_C.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Extracting EDF parameters from c:\\Users\\ryoii\\Desktop\\EEG2IMAGE\\data\\Envisioned_Speech_Recognition\\Char\\Nishant_F.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Extracting EDF parameters from c:\\Users\\ryoii\\Desktop\\EEG2IMAGE\\data\\Envisioned_Speech_Recognition\\Char\\Nishant_H.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Extracting EDF parameters from c:\\Users\\ryoii\\Desktop\\EEG2IMAGE\\data\\Envisioned_Speech_Recognition\\Char\\Nishant_J.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Extracting EDF parameters from c:\\Users\\ryoii\\Desktop\\EEG2IMAGE\\data\\Envisioned_Speech_Recognition\\Char\\Nishant_M.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Extracting EDF parameters from c:\\Users\\ryoii\\Desktop\\EEG2IMAGE\\data\\Envisioned_Speech_Recognition\\Char\\Nishant_P.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Extracting EDF parameters from c:\\Users\\ryoii\\Desktop\\EEG2IMAGE\\data\\Envisioned_Speech_Recognition\\Char\\Nishant_S.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Extracting EDF parameters from c:\\Users\\ryoii\\Desktop\\EEG2IMAGE\\data\\Envisioned_Speech_Recognition\\Char\\Nishant_T.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Extracting EDF parameters from c:\\Users\\ryoii\\Desktop\\EEG2IMAGE\\data\\Envisioned_Speech_Recognition\\Char\\Nishant_Y.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Extracting EDF parameters from c:\\Users\\ryoii\\Desktop\\EEG2IMAGE\\data\\Envisioned_Speech_Recognition\\Char\\Piyush_A.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Extracting EDF parameters from c:\\Users\\ryoii\\Desktop\\EEG2IMAGE\\data\\Envisioned_Speech_Recognition\\Char\\Piyush_C.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Extracting EDF parameters from c:\\Users\\ryoii\\Desktop\\EEG2IMAGE\\data\\Envisioned_Speech_Recognition\\Char\\Piyush_F.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Extracting EDF parameters from c:\\Users\\ryoii\\Desktop\\EEG2IMAGE\\data\\Envisioned_Speech_Recognition\\Char\\Piyush_H.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Extracting EDF parameters from c:\\Users\\ryoii\\Desktop\\EEG2IMAGE\\data\\Envisioned_Speech_Recognition\\Char\\Piyush_J.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Extracting EDF parameters from c:\\Users\\ryoii\\Desktop\\EEG2IMAGE\\data\\Envisioned_Speech_Recognition\\Char\\Piyush_M.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Extracting EDF parameters from c:\\Users\\ryoii\\Desktop\\EEG2IMAGE\\data\\Envisioned_Speech_Recognition\\Char\\Piyush_P.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Extracting EDF parameters from c:\\Users\\ryoii\\Desktop\\EEG2IMAGE\\data\\Envisioned_Speech_Recognition\\Char\\Piyush_S.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Extracting EDF parameters from c:\\Users\\ryoii\\Desktop\\EEG2IMAGE\\data\\Envisioned_Speech_Recognition\\Char\\Piyush_T.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Extracting EDF parameters from c:\\Users\\ryoii\\Desktop\\EEG2IMAGE\\data\\Envisioned_Speech_Recognition\\Char\\Piyush_Y.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Extracting EDF parameters from c:\\Users\\ryoii\\Desktop\\EEG2IMAGE\\data\\Envisioned_Speech_Recognition\\Char\\Pradeep_A.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Extracting EDF parameters from c:\\Users\\ryoii\\Desktop\\EEG2IMAGE\\data\\Envisioned_Speech_Recognition\\Char\\Pradeep_C.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Extracting EDF parameters from c:\\Users\\ryoii\\Desktop\\EEG2IMAGE\\data\\Envisioned_Speech_Recognition\\Char\\Pradeep_F.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Extracting EDF parameters from c:\\Users\\ryoii\\Desktop\\EEG2IMAGE\\data\\Envisioned_Speech_Recognition\\Char\\Pradeep_H.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Extracting EDF parameters from c:\\Users\\ryoii\\Desktop\\EEG2IMAGE\\data\\Envisioned_Speech_Recognition\\Char\\Pradeep_J.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Extracting EDF parameters from c:\\Users\\ryoii\\Desktop\\EEG2IMAGE\\data\\Envisioned_Speech_Recognition\\Char\\Pradeep_M.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Extracting EDF parameters from c:\\Users\\ryoii\\Desktop\\EEG2IMAGE\\data\\Envisioned_Speech_Recognition\\Char\\Pradeep_P.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Extracting EDF parameters from c:\\Users\\ryoii\\Desktop\\EEG2IMAGE\\data\\Envisioned_Speech_Recognition\\Char\\Pradeep_S.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Extracting EDF parameters from c:\\Users\\ryoii\\Desktop\\EEG2IMAGE\\data\\Envisioned_Speech_Recognition\\Char\\Pradeep_T.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Extracting EDF parameters from c:\\Users\\ryoii\\Desktop\\EEG2IMAGE\\data\\Envisioned_Speech_Recognition\\Char\\Pradeep_Y.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Extracting EDF parameters from c:\\Users\\ryoii\\Desktop\\EEG2IMAGE\\data\\Envisioned_Speech_Recognition\\Char\\Prateek_A.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Extracting EDF parameters from c:\\Users\\ryoii\\Desktop\\EEG2IMAGE\\data\\Envisioned_Speech_Recognition\\Char\\Prateek_C.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Extracting EDF parameters from c:\\Users\\ryoii\\Desktop\\EEG2IMAGE\\data\\Envisioned_Speech_Recognition\\Char\\Prateek_F.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Extracting EDF parameters from c:\\Users\\ryoii\\Desktop\\EEG2IMAGE\\data\\Envisioned_Speech_Recognition\\Char\\Prateek_H.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Extracting EDF parameters from c:\\Users\\ryoii\\Desktop\\EEG2IMAGE\\data\\Envisioned_Speech_Recognition\\Char\\Prateek_J.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Extracting EDF parameters from c:\\Users\\ryoii\\Desktop\\EEG2IMAGE\\data\\Envisioned_Speech_Recognition\\Char\\Prateek_M.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Extracting EDF parameters from c:\\Users\\ryoii\\Desktop\\EEG2IMAGE\\data\\Envisioned_Speech_Recognition\\Char\\Prateek_P.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Extracting EDF parameters from c:\\Users\\ryoii\\Desktop\\EEG2IMAGE\\data\\Envisioned_Speech_Recognition\\Char\\Prateek_S.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Extracting EDF parameters from c:\\Users\\ryoii\\Desktop\\EEG2IMAGE\\data\\Envisioned_Speech_Recognition\\Char\\Prateek_T.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Extracting EDF parameters from c:\\Users\\ryoii\\Desktop\\EEG2IMAGE\\data\\Envisioned_Speech_Recognition\\Char\\Prateek_Y.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Extracting EDF parameters from c:\\Users\\ryoii\\Desktop\\EEG2IMAGE\\data\\Envisioned_Speech_Recognition\\Char\\Rajkumar_A.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Extracting EDF parameters from c:\\Users\\ryoii\\Desktop\\EEG2IMAGE\\data\\Envisioned_Speech_Recognition\\Char\\Rajkumar_C.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Extracting EDF parameters from c:\\Users\\ryoii\\Desktop\\EEG2IMAGE\\data\\Envisioned_Speech_Recognition\\Char\\Rajkumar_F.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Extracting EDF parameters from c:\\Users\\ryoii\\Desktop\\EEG2IMAGE\\data\\Envisioned_Speech_Recognition\\Char\\Rajkumar_H.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Extracting EDF parameters from c:\\Users\\ryoii\\Desktop\\EEG2IMAGE\\data\\Envisioned_Speech_Recognition\\Char\\Rajkumar_J.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Extracting EDF parameters from c:\\Users\\ryoii\\Desktop\\EEG2IMAGE\\data\\Envisioned_Speech_Recognition\\Char\\Rajkumar_M.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Extracting EDF parameters from c:\\Users\\ryoii\\Desktop\\EEG2IMAGE\\data\\Envisioned_Speech_Recognition\\Char\\Rajkumar_P.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Extracting EDF parameters from c:\\Users\\ryoii\\Desktop\\EEG2IMAGE\\data\\Envisioned_Speech_Recognition\\Char\\Rajkumar_S.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Extracting EDF parameters from c:\\Users\\ryoii\\Desktop\\EEG2IMAGE\\data\\Envisioned_Speech_Recognition\\Char\\Rajkumar_T.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Extracting EDF parameters from c:\\Users\\ryoii\\Desktop\\EEG2IMAGE\\data\\Envisioned_Speech_Recognition\\Char\\Rajkumar_Y.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Extracting EDF parameters from c:\\Users\\ryoii\\Desktop\\EEG2IMAGE\\data\\Envisioned_Speech_Recognition\\Char\\rakesh_A.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Extracting EDF parameters from c:\\Users\\ryoii\\Desktop\\EEG2IMAGE\\data\\Envisioned_Speech_Recognition\\Char\\rakesh_C.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Extracting EDF parameters from c:\\Users\\ryoii\\Desktop\\EEG2IMAGE\\data\\Envisioned_Speech_Recognition\\Char\\rakesh_F.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Extracting EDF parameters from c:\\Users\\ryoii\\Desktop\\EEG2IMAGE\\data\\Envisioned_Speech_Recognition\\Char\\rakesh_H.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Extracting EDF parameters from c:\\Users\\ryoii\\Desktop\\EEG2IMAGE\\data\\Envisioned_Speech_Recognition\\Char\\rakesh_J.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Extracting EDF parameters from c:\\Users\\ryoii\\Desktop\\EEG2IMAGE\\data\\Envisioned_Speech_Recognition\\Char\\rakesh_M.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Extracting EDF parameters from c:\\Users\\ryoii\\Desktop\\EEG2IMAGE\\data\\Envisioned_Speech_Recognition\\Char\\rakesh_P.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Extracting EDF parameters from c:\\Users\\ryoii\\Desktop\\EEG2IMAGE\\data\\Envisioned_Speech_Recognition\\Char\\rakesh_S.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Extracting EDF parameters from c:\\Users\\ryoii\\Desktop\\EEG2IMAGE\\data\\Envisioned_Speech_Recognition\\Char\\rakesh_T.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Extracting EDF parameters from c:\\Users\\ryoii\\Desktop\\EEG2IMAGE\\data\\Envisioned_Speech_Recognition\\Char\\rakesh_Y.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Extracting EDF parameters from c:\\Users\\ryoii\\Desktop\\EEG2IMAGE\\data\\Envisioned_Speech_Recognition\\Char\\sachin_A.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Extracting EDF parameters from c:\\Users\\ryoii\\Desktop\\EEG2IMAGE\\data\\Envisioned_Speech_Recognition\\Char\\sachin_C.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Extracting EDF parameters from c:\\Users\\ryoii\\Desktop\\EEG2IMAGE\\data\\Envisioned_Speech_Recognition\\Char\\sachin_F.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Extracting EDF parameters from c:\\Users\\ryoii\\Desktop\\EEG2IMAGE\\data\\Envisioned_Speech_Recognition\\Char\\sachin_H.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Extracting EDF parameters from c:\\Users\\ryoii\\Desktop\\EEG2IMAGE\\data\\Envisioned_Speech_Recognition\\Char\\sachin_J.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Extracting EDF parameters from c:\\Users\\ryoii\\Desktop\\EEG2IMAGE\\data\\Envisioned_Speech_Recognition\\Char\\sachin_M.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Extracting EDF parameters from c:\\Users\\ryoii\\Desktop\\EEG2IMAGE\\data\\Envisioned_Speech_Recognition\\Char\\sachin_P.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Extracting EDF parameters from c:\\Users\\ryoii\\Desktop\\EEG2IMAGE\\data\\Envisioned_Speech_Recognition\\Char\\sachin_S.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Extracting EDF parameters from c:\\Users\\ryoii\\Desktop\\EEG2IMAGE\\data\\Envisioned_Speech_Recognition\\Char\\sachin_T.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Extracting EDF parameters from c:\\Users\\ryoii\\Desktop\\EEG2IMAGE\\data\\Envisioned_Speech_Recognition\\Char\\sachin_Y.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Extracting EDF parameters from c:\\Users\\ryoii\\Desktop\\EEG2IMAGE\\data\\Envisioned_Speech_Recognition\\Char\\samar_A.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Extracting EDF parameters from c:\\Users\\ryoii\\Desktop\\EEG2IMAGE\\data\\Envisioned_Speech_Recognition\\Char\\samar_C.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Extracting EDF parameters from c:\\Users\\ryoii\\Desktop\\EEG2IMAGE\\data\\Envisioned_Speech_Recognition\\Char\\samar_F.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Extracting EDF parameters from c:\\Users\\ryoii\\Desktop\\EEG2IMAGE\\data\\Envisioned_Speech_Recognition\\Char\\samar_H.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Extracting EDF parameters from c:\\Users\\ryoii\\Desktop\\EEG2IMAGE\\data\\Envisioned_Speech_Recognition\\Char\\samar_J.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Extracting EDF parameters from c:\\Users\\ryoii\\Desktop\\EEG2IMAGE\\data\\Envisioned_Speech_Recognition\\Char\\samar_M.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Extracting EDF parameters from c:\\Users\\ryoii\\Desktop\\EEG2IMAGE\\data\\Envisioned_Speech_Recognition\\Char\\samar_P.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Extracting EDF parameters from c:\\Users\\ryoii\\Desktop\\EEG2IMAGE\\data\\Envisioned_Speech_Recognition\\Char\\samar_S.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Extracting EDF parameters from c:\\Users\\ryoii\\Desktop\\EEG2IMAGE\\data\\Envisioned_Speech_Recognition\\Char\\samar_T.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Extracting EDF parameters from c:\\Users\\ryoii\\Desktop\\EEG2IMAGE\\data\\Envisioned_Speech_Recognition\\Char\\samar_Y.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Extracting EDF parameters from c:\\Users\\ryoii\\Desktop\\EEG2IMAGE\\data\\Envisioned_Speech_Recognition\\Char\\shubhamtiwari_A.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Extracting EDF parameters from c:\\Users\\ryoii\\Desktop\\EEG2IMAGE\\data\\Envisioned_Speech_Recognition\\Char\\shubhamtiwari_C.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Extracting EDF parameters from c:\\Users\\ryoii\\Desktop\\EEG2IMAGE\\data\\Envisioned_Speech_Recognition\\Char\\shubhamtiwari_F.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Extracting EDF parameters from c:\\Users\\ryoii\\Desktop\\EEG2IMAGE\\data\\Envisioned_Speech_Recognition\\Char\\shubhamtiwari_H.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Extracting EDF parameters from c:\\Users\\ryoii\\Desktop\\EEG2IMAGE\\data\\Envisioned_Speech_Recognition\\Char\\shubhamtiwari_J.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Extracting EDF parameters from c:\\Users\\ryoii\\Desktop\\EEG2IMAGE\\data\\Envisioned_Speech_Recognition\\Char\\shubhamtiwari_M.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Extracting EDF parameters from c:\\Users\\ryoii\\Desktop\\EEG2IMAGE\\data\\Envisioned_Speech_Recognition\\Char\\shubhamtiwari_P.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Extracting EDF parameters from c:\\Users\\ryoii\\Desktop\\EEG2IMAGE\\data\\Envisioned_Speech_Recognition\\Char\\shubhamtiwari_S.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Extracting EDF parameters from c:\\Users\\ryoii\\Desktop\\EEG2IMAGE\\data\\Envisioned_Speech_Recognition\\Char\\shubhamtiwari_T.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Extracting EDF parameters from c:\\Users\\ryoii\\Desktop\\EEG2IMAGE\\data\\Envisioned_Speech_Recognition\\Char\\shubhamtiwari_Y.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Extracting EDF parameters from c:\\Users\\ryoii\\Desktop\\EEG2IMAGE\\data\\Envisioned_Speech_Recognition\\Char\\shweta_A.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Extracting EDF parameters from c:\\Users\\ryoii\\Desktop\\EEG2IMAGE\\data\\Envisioned_Speech_Recognition\\Char\\shweta_C.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Extracting EDF parameters from c:\\Users\\ryoii\\Desktop\\EEG2IMAGE\\data\\Envisioned_Speech_Recognition\\Char\\shweta_F.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Extracting EDF parameters from c:\\Users\\ryoii\\Desktop\\EEG2IMAGE\\data\\Envisioned_Speech_Recognition\\Char\\shweta_H.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Extracting EDF parameters from c:\\Users\\ryoii\\Desktop\\EEG2IMAGE\\data\\Envisioned_Speech_Recognition\\Char\\shweta_J.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Extracting EDF parameters from c:\\Users\\ryoii\\Desktop\\EEG2IMAGE\\data\\Envisioned_Speech_Recognition\\Char\\shweta_M.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Extracting EDF parameters from c:\\Users\\ryoii\\Desktop\\EEG2IMAGE\\data\\Envisioned_Speech_Recognition\\Char\\shweta_P.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Extracting EDF parameters from c:\\Users\\ryoii\\Desktop\\EEG2IMAGE\\data\\Envisioned_Speech_Recognition\\Char\\shweta_S.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Extracting EDF parameters from c:\\Users\\ryoii\\Desktop\\EEG2IMAGE\\data\\Envisioned_Speech_Recognition\\Char\\shweta_T.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Extracting EDF parameters from c:\\Users\\ryoii\\Desktop\\EEG2IMAGE\\data\\Envisioned_Speech_Recognition\\Char\\shweta_Y.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Extracting EDF parameters from c:\\Users\\ryoii\\Desktop\\EEG2IMAGE\\data\\Envisioned_Speech_Recognition\\Char\\Srishti_A.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Extracting EDF parameters from c:\\Users\\ryoii\\Desktop\\EEG2IMAGE\\data\\Envisioned_Speech_Recognition\\Char\\Srishti_C.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Extracting EDF parameters from c:\\Users\\ryoii\\Desktop\\EEG2IMAGE\\data\\Envisioned_Speech_Recognition\\Char\\Srishti_F.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Extracting EDF parameters from c:\\Users\\ryoii\\Desktop\\EEG2IMAGE\\data\\Envisioned_Speech_Recognition\\Char\\Srishti_H.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Extracting EDF parameters from c:\\Users\\ryoii\\Desktop\\EEG2IMAGE\\data\\Envisioned_Speech_Recognition\\Char\\Srishti_J.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Extracting EDF parameters from c:\\Users\\ryoii\\Desktop\\EEG2IMAGE\\data\\Envisioned_Speech_Recognition\\Char\\Srishti_M.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Extracting EDF parameters from c:\\Users\\ryoii\\Desktop\\EEG2IMAGE\\data\\Envisioned_Speech_Recognition\\Char\\Srishti_P.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Extracting EDF parameters from c:\\Users\\ryoii\\Desktop\\EEG2IMAGE\\data\\Envisioned_Speech_Recognition\\Char\\Srishti_S.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Extracting EDF parameters from c:\\Users\\ryoii\\Desktop\\EEG2IMAGE\\data\\Envisioned_Speech_Recognition\\Char\\Srishti_T.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Extracting EDF parameters from c:\\Users\\ryoii\\Desktop\\EEG2IMAGE\\data\\Envisioned_Speech_Recognition\\Char\\Srishti_Y.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Extracting EDF parameters from c:\\Users\\ryoii\\Desktop\\EEG2IMAGE\\data\\Envisioned_Speech_Recognition\\Char\\Udit_A.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Extracting EDF parameters from c:\\Users\\ryoii\\Desktop\\EEG2IMAGE\\data\\Envisioned_Speech_Recognition\\Char\\Udit_C.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Extracting EDF parameters from c:\\Users\\ryoii\\Desktop\\EEG2IMAGE\\data\\Envisioned_Speech_Recognition\\Char\\Udit_F.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Extracting EDF parameters from c:\\Users\\ryoii\\Desktop\\EEG2IMAGE\\data\\Envisioned_Speech_Recognition\\Char\\Udit_H.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Extracting EDF parameters from c:\\Users\\ryoii\\Desktop\\EEG2IMAGE\\data\\Envisioned_Speech_Recognition\\Char\\Udit_J.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Extracting EDF parameters from c:\\Users\\ryoii\\Desktop\\EEG2IMAGE\\data\\Envisioned_Speech_Recognition\\Char\\Udit_M.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Extracting EDF parameters from c:\\Users\\ryoii\\Desktop\\EEG2IMAGE\\data\\Envisioned_Speech_Recognition\\Char\\Udit_P.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Extracting EDF parameters from c:\\Users\\ryoii\\Desktop\\EEG2IMAGE\\data\\Envisioned_Speech_Recognition\\Char\\Udit_S.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Extracting EDF parameters from c:\\Users\\ryoii\\Desktop\\EEG2IMAGE\\data\\Envisioned_Speech_Recognition\\Char\\Udit_T.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Extracting EDF parameters from c:\\Users\\ryoii\\Desktop\\EEG2IMAGE\\data\\Envisioned_Speech_Recognition\\Char\\Udit_Y.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Extracting EDF parameters from c:\\Users\\ryoii\\Desktop\\EEG2IMAGE\\data\\Envisioned_Speech_Recognition\\Char\\VikasPHD_A.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Extracting EDF parameters from c:\\Users\\ryoii\\Desktop\\EEG2IMAGE\\data\\Envisioned_Speech_Recognition\\Char\\VikasPHD_C.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Extracting EDF parameters from c:\\Users\\ryoii\\Desktop\\EEG2IMAGE\\data\\Envisioned_Speech_Recognition\\Char\\VikasPHD_F.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Extracting EDF parameters from c:\\Users\\ryoii\\Desktop\\EEG2IMAGE\\data\\Envisioned_Speech_Recognition\\Char\\VikasPHD_H.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Extracting EDF parameters from c:\\Users\\ryoii\\Desktop\\EEG2IMAGE\\data\\Envisioned_Speech_Recognition\\Char\\VikasPHD_J.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Extracting EDF parameters from c:\\Users\\ryoii\\Desktop\\EEG2IMAGE\\data\\Envisioned_Speech_Recognition\\Char\\VikasPHD_M.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Extracting EDF parameters from c:\\Users\\ryoii\\Desktop\\EEG2IMAGE\\data\\Envisioned_Speech_Recognition\\Char\\VikasPHD_P.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Extracting EDF parameters from c:\\Users\\ryoii\\Desktop\\EEG2IMAGE\\data\\Envisioned_Speech_Recognition\\Char\\VikasPHD_S.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Extracting EDF parameters from c:\\Users\\ryoii\\Desktop\\EEG2IMAGE\\data\\Envisioned_Speech_Recognition\\Char\\VikasPHD_T.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Extracting EDF parameters from c:\\Users\\ryoii\\Desktop\\EEG2IMAGE\\data\\Envisioned_Speech_Recognition\\Char\\VikasPHD_Y.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Extracting EDF parameters from c:\\Users\\ryoii\\Desktop\\EEG2IMAGE\\data\\Envisioned_Speech_Recognition\\Char\\Vipin_A.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Extracting EDF parameters from c:\\Users\\ryoii\\Desktop\\EEG2IMAGE\\data\\Envisioned_Speech_Recognition\\Char\\Vipin_C.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Extracting EDF parameters from c:\\Users\\ryoii\\Desktop\\EEG2IMAGE\\data\\Envisioned_Speech_Recognition\\Char\\Vipin_F.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Extracting EDF parameters from c:\\Users\\ryoii\\Desktop\\EEG2IMAGE\\data\\Envisioned_Speech_Recognition\\Char\\Vipin_H.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Extracting EDF parameters from c:\\Users\\ryoii\\Desktop\\EEG2IMAGE\\data\\Envisioned_Speech_Recognition\\Char\\Vipin_J.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Extracting EDF parameters from c:\\Users\\ryoii\\Desktop\\EEG2IMAGE\\data\\Envisioned_Speech_Recognition\\Char\\Vipin_M.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Extracting EDF parameters from c:\\Users\\ryoii\\Desktop\\EEG2IMAGE\\data\\Envisioned_Speech_Recognition\\Char\\Vipin_P.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Extracting EDF parameters from c:\\Users\\ryoii\\Desktop\\EEG2IMAGE\\data\\Envisioned_Speech_Recognition\\Char\\Vipin_S.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Extracting EDF parameters from c:\\Users\\ryoii\\Desktop\\EEG2IMAGE\\data\\Envisioned_Speech_Recognition\\Char\\Vipin_T.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Extracting EDF parameters from c:\\Users\\ryoii\\Desktop\\EEG2IMAGE\\data\\Envisioned_Speech_Recognition\\Char\\Vipin_Y.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "shape of X : (230, 14, 1280)\n",
      "shape of Y : (230,)\n",
      "['AF3', 'F7', 'F3', 'FC5', 'T7', 'P7', 'O1', 'O2', 'P8', 'T8', 'FC6', 'F4', 'F8', 'AF4']\n"
     ]
    }
   ],
   "source": [
    "X, Y, channels = load_alphabet(fo)\n",
    "print(f'shape of X : {X.shape}')\n",
    "print(f'shape of Y : {Y.shape}')\n",
    "print(channels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "250ef01d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #  Moving Average filter\n",
    "# selected_channels = [4,9]\n",
    "# dataset_type = 'alphabet_MA2'\n",
    "# channels  = 'two_channel'\n",
    "# X_new, Y_new = transform_eeg_data(X, Y, selected_channels, npt=34)\n",
    "# print(X_new.shape)\n",
    "# plot_eeg(X_new)\n",
    "\n",
    "# X_filtered = MA_X2(X_new, axis=1, M=3)\n",
    "# plot_eeg(X_filtered)\n",
    "\n",
    "\n",
    "# model = train(X_filtered, Y_new, selected_channels, dataset_type=dataset_type, epochs=500, channels=channels)\n",
    "# visualize(model, X_filtered, Y_new, selected_channels, dataset_type=dataset_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "122421c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #  Butterworth filter\n",
    "# selected_channels = [4,9]\n",
    "# dataset_type = 'alphabet_BW'\n",
    "# channels  = 'two_channel'\n",
    "# X_new, Y_new = transform_eeg_data(X, Y, selected_channels)\n",
    "# print(X_new.shape)\n",
    "# plot_eeg(X_new)\n",
    "# X_filtered = butterworth_highpass_filter(X_new, cutoff=15, fs=128, order=2, axis=1)\n",
    "# print(X_filtered.shape)\n",
    "# plot_eeg(X_filtered)\n",
    "\n",
    "# model = train(X_filtered, Y_new, selected_channels, dataset_type=dataset_type, epochs=500, channels=channels)\n",
    "# visualize(model, X_filtered, Y_new, selected_channels, dataset_type=dataset_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2965cea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #  notch filter\n",
    "# selected_channels = [4,9]\n",
    "# dataset_type = 'alphabet_N'\n",
    "# channels  = 'two_channel'\n",
    "# X_new, Y_new = transform_eeg_data(X, Y, selected_channels)\n",
    "# print(X_new.shape)\n",
    "# plot_eeg(X_new)\n",
    "# X_filtered = notch_filter(X_new, freq=60.0, fs=128, Q=30.0, axis=1)\n",
    "# print(X_filtered.shape)\n",
    "# plot_eeg(X_filtered)\n",
    "\n",
    "# model = train(X_filtered, Y_new, selected_channels, dataset_type=dataset_type, epochs=500, channels=channels)\n",
    "# visualize(model, X_filtered, Y_new, selected_channels, dataset_type=dataset_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "655b441c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #  Z-score standardization\n",
    "# selected_channels = [4,9]\n",
    "# dataset_type = 'alphabet_Z'\n",
    "# channels  = 'two_channel'\n",
    "# X_new, Y_new = transform_eeg_data(X, Y, selected_channels)\n",
    "# print(X_new.shape)\n",
    "# plot_eeg(X_new)\n",
    "# X_standardized = zscore_standardize(X_new, axis=1)\n",
    "# plot_eeg(X_standardized)\n",
    "\n",
    "# model = train(X_standardized, Y_new, selected_channels, dataset_type=dataset_type, epochs=500, channels=channels)\n",
    "# visualize(model, X_standardized, Y_new, selected_channels, dataset_type=dataset_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b837b819",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #  daubechies dwt\n",
    "# selected_channels = [4,9]\n",
    "# dataset_type = 'alphabet_DWT'\n",
    "# channels  = 'two_channel'\n",
    "# X_new, Y_new = transform_eeg_data(X, Y, selected_channels)\n",
    "# print(X_new.shape)\n",
    "# plot_eeg(X_new)\n",
    "# X_reconstructed = dwt_reconstruct(X_new, threshold=0.01)\n",
    "# plot_eeg(X_reconstructed)\n",
    "\n",
    "# model = train(X_reconstructed, Y_new, selected_channels, dataset_type=dataset_type, epochs=500, channels=channels)\n",
    "# visualize(model, X_reconstructed, Y_new, selected_channels, dataset_type=dataset_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8756e6c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #  Min-max scaling\n",
    "# selected_channels = [4,9]\n",
    "# dataset_type = 'alphabet_mm'\n",
    "# channels  = 'two_channel'\n",
    "# X_new, Y_new = transform_eeg_data(X, Y, selected_channels)\n",
    "# print(X_new.shape)\n",
    "# plot_eeg(X_new)\n",
    "# X_standardized = minmax_scale(X_new, axis=1)\n",
    "# plot_eeg(X_standardized)\n",
    "\n",
    "# model = train(X_standardized, Y_new, selected_channels, dataset_type=dataset_type, epochs=500, channels=channels)\n",
    "# visualize(model, X_standardized, Y_new, selected_channels, dataset_type=dataset_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "346a4014",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #  ICA extraction\n",
    "# selected_channels = [4,9]\n",
    "# dataset_type = 'alphabet_ICA'\n",
    "# channels  = 'two_channel'\n",
    "# X_ICA = apply_ica_eeg(X)\n",
    "# X_new, Y_new = transform_eeg_data(X_ICA, Y, selected_channels)\n",
    "# plot_eeg(X_new)\n",
    "# model = train(X_new, Y_new, selected_channels, dataset_type=dataset_type, epochs=500, channels=channels)\n",
    "# visualize(model, X_new, Y_new, selected_channels, dataset_type=dataset_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "96df730b",
   "metadata": {},
   "outputs": [],
   "source": [
    "THETA = (4, 7)\n",
    "ALPHA = (7, 15)\n",
    "BETA = (15, 31)\n",
    "GAMMA = (31, None)\n",
    "BETAGAMMA = (15, None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2f1b3b17",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "train() got multiple values for argument 'dataset_type'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [8]\u001b[0m, in \u001b[0;36m<cell line: 7>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      4\u001b[0m channels  \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtwo_channel\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m      5\u001b[0m X_new, Y_new \u001b[38;5;241m=\u001b[39m process_band(X, Y, l_freq\u001b[38;5;241m=\u001b[39mGAMMA[\u001b[38;5;241m0\u001b[39m], h_freq\u001b[38;5;241m=\u001b[39mGAMMA[\u001b[38;5;241m1\u001b[39m])\n\u001b[1;32m----> 7\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_new\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY_new\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mselected_channels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataset_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdataset_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m50\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mtype\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mGAMMA\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchannels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchannels\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      8\u001b[0m visualize(model, X_new, Y_new, selected_channels, dataset_type\u001b[38;5;241m=\u001b[39mdataset_type)\n",
      "\u001b[1;31mTypeError\u001b[0m: train() got multiple values for argument 'dataset_type'"
     ]
    }
   ],
   "source": [
    "# Gamma\n",
    "selected_channels = [4,9]\n",
    "dataset_type = 'alphabet'\n",
    "channels  = 'two_channel'\n",
    "X_new, Y_new = process_band(X, Y, l_freq=GAMMA[0], h_freq=GAMMA[1])\n",
    "\n",
    "model = train(X_new, Y_new, selected_channels, dataset_type=dataset_type, epochs=50, type='GAMMA', channels=channels)\n",
    "visualize(model, X_new, Y_new, selected_channels, dataset_type=dataset_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8cb1fbfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # BETA\n",
    "# selected_channels = [4,9]\n",
    "# dataset_type = 'alphabet'\n",
    "# channels  = 'two_channel'\n",
    "# X_new, Y_new = process_band(X, Y, l_freq=BETA[0], h_freq=BETA[1])\n",
    "\n",
    "# model = train(X_new, Y_new, selected_channels, dataset_type=dataset_type, epochs=50, type='BETA', channels=channels)\n",
    "# visualize(model, X_new, Y_new, selected_channels, dataset_type=dataset_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "44c04253",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Late Fusion\n",
    "# selected_channels = [4,9]\n",
    "# dataset_type = 'alphabet'\n",
    "# channels  = 'two_channel'\n",
    "# X_GAMMA, Y_FINAL = process_band(X, Y, l_freq=GAMMA[0], h_freq=GAMMA[1])\n",
    "# X_BETA, Y_FINAL = process_band(X, Y, l_freq=BETA[0], h_freq=BETA[1])\n",
    "\n",
    "# late_fusion_accuracy = train_LateFusion(\n",
    "#     X_GAMMA, X_BETA, Y_FINAL, selected_channels=[4, 9], dataset_type='alphabet', num_classes=10, epochs=500, batch_size=128\n",
    "# )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a19642bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "\u001b[1m181/181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - accuracy: 0.1153 - loss: 2.5754\n",
      "Epoch 1: val_loss improved from inf to 2.30905, saving model to model/two_channel/model_alphabet_GAMMA.keras\n",
      "\u001b[1m181/181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 77ms/step - accuracy: 0.1153 - loss: 2.5744 - val_accuracy: 0.1028 - val_loss: 2.3091\n",
      "Epoch 2/500\n",
      "\u001b[1m180/181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - accuracy: 0.1601 - loss: 2.2275\n",
      "Epoch 2: val_loss did not improve from 2.30905\n",
      "\u001b[1m181/181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 79ms/step - accuracy: 0.1602 - loss: 2.2271 - val_accuracy: 0.0993 - val_loss: 2.4310\n",
      "Epoch 3/500\n",
      "\u001b[1m180/181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - accuracy: 0.2122 - loss: 2.0555\n",
      "Epoch 3: val_loss did not improve from 2.30905\n",
      "\u001b[1m181/181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 70ms/step - accuracy: 0.2123 - loss: 2.0551 - val_accuracy: 0.1064 - val_loss: 2.5194\n",
      "Epoch 4/500\n",
      "\u001b[1m180/181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - accuracy: 0.2499 - loss: 1.9338\n",
      "Epoch 4: val_loss improved from 2.30905 to 2.26156, saving model to model/two_channel/model_alphabet_GAMMA.keras\n",
      "\u001b[1m181/181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 65ms/step - accuracy: 0.2500 - loss: 1.9334 - val_accuracy: 0.1835 - val_loss: 2.2616\n",
      "Epoch 5/500\n",
      "\u001b[1m180/181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - accuracy: 0.2962 - loss: 1.8086\n",
      "Epoch 5: val_loss improved from 2.26156 to 1.71558, saving model to model/two_channel/model_alphabet_GAMMA.keras\n",
      "\u001b[1m181/181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 76ms/step - accuracy: 0.2962 - loss: 1.8084 - val_accuracy: 0.3101 - val_loss: 1.7156\n",
      "Epoch 6/500\n",
      "\u001b[1m180/181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - accuracy: 0.3339 - loss: 1.6825\n",
      "Epoch 6: val_loss improved from 1.71558 to 1.69200, saving model to model/two_channel/model_alphabet_GAMMA.keras\n",
      "\u001b[1m181/181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 69ms/step - accuracy: 0.3340 - loss: 1.6824 - val_accuracy: 0.3242 - val_loss: 1.6920\n",
      "Epoch 7/500\n",
      "\u001b[1m180/181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - accuracy: 0.3814 - loss: 1.5665\n",
      "Epoch 7: val_loss improved from 1.69200 to 1.59669, saving model to model/two_channel/model_alphabet_GAMMA.keras\n",
      "\u001b[1m181/181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 68ms/step - accuracy: 0.3813 - loss: 1.5666 - val_accuracy: 0.3423 - val_loss: 1.5967\n",
      "Epoch 8/500\n",
      "\u001b[1m180/181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - accuracy: 0.3948 - loss: 1.5235\n",
      "Epoch 8: val_loss improved from 1.59669 to 1.49722, saving model to model/two_channel/model_alphabet_GAMMA.keras\n",
      "\u001b[1m181/181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 75ms/step - accuracy: 0.3948 - loss: 1.5235 - val_accuracy: 0.4033 - val_loss: 1.4972\n",
      "Epoch 9/500\n",
      "\u001b[1m180/181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - accuracy: 0.4105 - loss: 1.4821\n",
      "Epoch 9: val_loss improved from 1.49722 to 1.43346, saving model to model/two_channel/model_alphabet_GAMMA.keras\n",
      "\u001b[1m181/181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 69ms/step - accuracy: 0.4106 - loss: 1.4818 - val_accuracy: 0.4263 - val_loss: 1.4335\n",
      "Epoch 10/500\n",
      "\u001b[1m181/181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - accuracy: 0.4345 - loss: 1.4031\n",
      "Epoch 10: val_loss improved from 1.43346 to 1.35471, saving model to model/two_channel/model_alphabet_GAMMA.keras\n",
      "\u001b[1m181/181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 68ms/step - accuracy: 0.4346 - loss: 1.4030 - val_accuracy: 0.4732 - val_loss: 1.3547\n",
      "Epoch 11/500\n",
      "\u001b[1m180/181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - accuracy: 0.4694 - loss: 1.3228\n",
      "Epoch 11: val_loss did not improve from 1.35471\n",
      "\u001b[1m181/181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 67ms/step - accuracy: 0.4694 - loss: 1.3229 - val_accuracy: 0.3832 - val_loss: 1.6161\n",
      "Epoch 12/500\n",
      "\u001b[1m181/181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - accuracy: 0.4802 - loss: 1.2925\n",
      "Epoch 12: val_loss improved from 1.35471 to 1.34002, saving model to model/two_channel/model_alphabet_GAMMA.keras\n",
      "\u001b[1m181/181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 71ms/step - accuracy: 0.4802 - loss: 1.2925 - val_accuracy: 0.4900 - val_loss: 1.3400\n",
      "Epoch 13/500\n",
      "\u001b[1m180/181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - accuracy: 0.5109 - loss: 1.2165\n",
      "Epoch 13: val_loss did not improve from 1.34002\n",
      "\u001b[1m181/181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 68ms/step - accuracy: 0.5109 - loss: 1.2166 - val_accuracy: 0.4244 - val_loss: 1.4092\n",
      "Epoch 14/500\n",
      "\u001b[1m180/181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - accuracy: 0.5272 - loss: 1.1955\n",
      "Epoch 14: val_loss improved from 1.34002 to 1.24637, saving model to model/two_channel/model_alphabet_GAMMA.keras\n",
      "\u001b[1m181/181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 68ms/step - accuracy: 0.5272 - loss: 1.1955 - val_accuracy: 0.4978 - val_loss: 1.2464\n",
      "Epoch 15/500\n",
      "\u001b[1m180/181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - accuracy: 0.5528 - loss: 1.1176\n",
      "Epoch 15: val_loss did not improve from 1.24637\n",
      "\u001b[1m181/181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 69ms/step - accuracy: 0.5527 - loss: 1.1178 - val_accuracy: 0.4882 - val_loss: 1.3250\n",
      "Epoch 16/500\n",
      "\u001b[1m180/181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - accuracy: 0.5668 - loss: 1.0806\n",
      "Epoch 16: val_loss did not improve from 1.24637\n",
      "\u001b[1m181/181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 69ms/step - accuracy: 0.5668 - loss: 1.0807 - val_accuracy: 0.5114 - val_loss: 1.2716\n",
      "Epoch 17/500\n",
      "\u001b[1m181/181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - accuracy: 0.5840 - loss: 1.0644\n",
      "Epoch 17: val_loss did not improve from 1.24637\n",
      "\u001b[1m181/181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 75ms/step - accuracy: 0.5840 - loss: 1.0644 - val_accuracy: 0.5251 - val_loss: 1.2768\n",
      "Epoch 18/500\n",
      "\u001b[1m180/181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - accuracy: 0.5939 - loss: 1.0185\n",
      "Epoch 18: val_loss improved from 1.24637 to 1.19446, saving model to model/two_channel/model_alphabet_GAMMA.keras\n",
      "\u001b[1m181/181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 70ms/step - accuracy: 0.5940 - loss: 1.0185 - val_accuracy: 0.5471 - val_loss: 1.1945\n",
      "Epoch 19/500\n",
      "\u001b[1m180/181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - accuracy: 0.6217 - loss: 0.9603\n",
      "Epoch 19: val_loss improved from 1.19446 to 1.06070, saving model to model/two_channel/model_alphabet_GAMMA.keras\n",
      "\u001b[1m181/181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 70ms/step - accuracy: 0.6216 - loss: 0.9604 - val_accuracy: 0.5938 - val_loss: 1.0607\n",
      "Epoch 20/500\n",
      "\u001b[1m180/181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - accuracy: 0.6455 - loss: 0.9024\n",
      "Epoch 20: val_loss did not improve from 1.06070\n",
      "\u001b[1m181/181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 68ms/step - accuracy: 0.6454 - loss: 0.9028 - val_accuracy: 0.5647 - val_loss: 1.1338\n",
      "Epoch 21/500\n",
      "\u001b[1m180/181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - accuracy: 0.6634 - loss: 0.8579\n",
      "Epoch 21: val_loss did not improve from 1.06070\n",
      "\u001b[1m181/181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 69ms/step - accuracy: 0.6634 - loss: 0.8580 - val_accuracy: 0.5711 - val_loss: 1.1187\n",
      "Epoch 22/500\n",
      "\u001b[1m180/181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - accuracy: 0.6752 - loss: 0.8408\n",
      "Epoch 22: val_loss did not improve from 1.06070\n",
      "\u001b[1m181/181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 68ms/step - accuracy: 0.6752 - loss: 0.8408 - val_accuracy: 0.5723 - val_loss: 1.1403\n",
      "Epoch 23/500\n",
      "\u001b[1m181/181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - accuracy: 0.6897 - loss: 0.8010\n",
      "Epoch 23: val_loss improved from 1.06070 to 1.04053, saving model to model/two_channel/model_alphabet_GAMMA.keras\n",
      "\u001b[1m181/181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 72ms/step - accuracy: 0.6897 - loss: 0.8011 - val_accuracy: 0.6205 - val_loss: 1.0405\n",
      "Epoch 24/500\n",
      "\u001b[1m180/181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - accuracy: 0.7113 - loss: 0.7500\n",
      "Epoch 24: val_loss did not improve from 1.04053\n",
      "\u001b[1m181/181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 68ms/step - accuracy: 0.7113 - loss: 0.7501 - val_accuracy: 0.5961 - val_loss: 1.1149\n",
      "Epoch 25/500\n",
      "\u001b[1m181/181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - accuracy: 0.7388 - loss: 0.6824\n",
      "Epoch 25: val_loss did not improve from 1.04053\n",
      "\u001b[1m181/181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 67ms/step - accuracy: 0.7388 - loss: 0.6825 - val_accuracy: 0.5869 - val_loss: 1.1508\n",
      "Epoch 26/500\n",
      "\u001b[1m180/181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - accuracy: 0.7442 - loss: 0.6744\n",
      "Epoch 26: val_loss did not improve from 1.04053\n",
      "\u001b[1m181/181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 67ms/step - accuracy: 0.7441 - loss: 0.6745 - val_accuracy: 0.6089 - val_loss: 1.1273\n",
      "Epoch 27/500\n",
      "\u001b[1m180/181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - accuracy: 0.7580 - loss: 0.6357\n",
      "Epoch 27: val_loss did not improve from 1.04053\n",
      "\u001b[1m181/181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 67ms/step - accuracy: 0.7581 - loss: 0.6356 - val_accuracy: 0.6161 - val_loss: 1.1167\n",
      "Epoch 28/500\n",
      "\u001b[1m181/181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - accuracy: 0.7816 - loss: 0.5859\n",
      "Epoch 28: val_loss did not improve from 1.04053\n",
      "\u001b[1m181/181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 68ms/step - accuracy: 0.7816 - loss: 0.5859 - val_accuracy: 0.6208 - val_loss: 1.1469\n",
      "Epoch 29/500\n",
      "\u001b[1m180/181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - accuracy: 0.7913 - loss: 0.5518\n",
      "Epoch 29: val_loss did not improve from 1.04053\n",
      "\u001b[1m181/181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 67ms/step - accuracy: 0.7913 - loss: 0.5520 - val_accuracy: 0.6440 - val_loss: 1.0674\n",
      "Epoch 30/500\n",
      "\u001b[1m180/181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - accuracy: 0.7940 - loss: 0.5482\n",
      "Epoch 30: val_loss did not improve from 1.04053\n",
      "\u001b[1m181/181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 67ms/step - accuracy: 0.7940 - loss: 0.5481 - val_accuracy: 0.6411 - val_loss: 1.1985\n",
      "Epoch 31/500\n",
      "\u001b[1m180/181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - accuracy: 0.8151 - loss: 0.5009\n",
      "Epoch 31: val_loss did not improve from 1.04053\n",
      "\u001b[1m181/181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 68ms/step - accuracy: 0.8151 - loss: 0.5009 - val_accuracy: 0.6388 - val_loss: 1.1434\n",
      "Epoch 32/500\n",
      "\u001b[1m180/181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - accuracy: 0.8337 - loss: 0.4391\n",
      "Epoch 32: val_loss did not improve from 1.04053\n",
      "\u001b[1m181/181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 67ms/step - accuracy: 0.8336 - loss: 0.4393 - val_accuracy: 0.6563 - val_loss: 1.1146\n",
      "Epoch 33/500\n",
      "\u001b[1m180/181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - accuracy: 0.8460 - loss: 0.4266\n",
      "Epoch 33: val_loss did not improve from 1.04053\n",
      "\u001b[1m181/181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 66ms/step - accuracy: 0.8459 - loss: 0.4268 - val_accuracy: 0.6715 - val_loss: 1.1253\n",
      "Epoch 34/500\n",
      "\u001b[1m180/181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - accuracy: 0.8581 - loss: 0.3879\n",
      "Epoch 34: val_loss did not improve from 1.04053\n",
      "\u001b[1m181/181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 66ms/step - accuracy: 0.8581 - loss: 0.3880 - val_accuracy: 0.6546 - val_loss: 1.1964\n",
      "Epoch 35/500\n",
      "\u001b[1m180/181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - accuracy: 0.8676 - loss: 0.3675\n",
      "Epoch 35: val_loss did not improve from 1.04053\n",
      "\u001b[1m181/181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 69ms/step - accuracy: 0.8675 - loss: 0.3677 - val_accuracy: 0.6490 - val_loss: 1.2171\n",
      "Epoch 36/500\n",
      "\u001b[1m180/181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - accuracy: 0.8753 - loss: 0.3461\n",
      "Epoch 36: val_loss did not improve from 1.04053\n",
      "\u001b[1m181/181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 64ms/step - accuracy: 0.8752 - loss: 0.3463 - val_accuracy: 0.6705 - val_loss: 1.1805\n",
      "Epoch 37/500\n",
      "\u001b[1m180/181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - accuracy: 0.8717 - loss: 0.3535\n",
      "Epoch 37: val_loss did not improve from 1.04053\n",
      "\u001b[1m181/181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 65ms/step - accuracy: 0.8717 - loss: 0.3534 - val_accuracy: 0.6525 - val_loss: 1.3147\n",
      "Epoch 38/500\n",
      "\u001b[1m180/181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - accuracy: 0.8806 - loss: 0.3351\n",
      "Epoch 38: val_loss did not improve from 1.04053\n",
      "\u001b[1m181/181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 65ms/step - accuracy: 0.8805 - loss: 0.3352 - val_accuracy: 0.6996 - val_loss: 1.0738\n",
      "Epoch 39/500\n",
      "\u001b[1m180/181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - accuracy: 0.8938 - loss: 0.3000\n",
      "Epoch 39: val_loss did not improve from 1.04053\n",
      "\u001b[1m181/181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 64ms/step - accuracy: 0.8938 - loss: 0.3000 - val_accuracy: 0.7011 - val_loss: 1.1484\n",
      "Epoch 40/500\n",
      "\u001b[1m180/181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - accuracy: 0.9033 - loss: 0.2654\n",
      "Epoch 40: val_loss did not improve from 1.04053\n",
      "\u001b[1m181/181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 67ms/step - accuracy: 0.9033 - loss: 0.2654 - val_accuracy: 0.6757 - val_loss: 1.2984\n",
      "Epoch 41/500\n",
      "\u001b[1m180/181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - accuracy: 0.9088 - loss: 0.2579\n",
      "Epoch 41: val_loss did not improve from 1.04053\n",
      "\u001b[1m181/181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 64ms/step - accuracy: 0.9087 - loss: 0.2580 - val_accuracy: 0.7011 - val_loss: 1.1612\n",
      "Epoch 42/500\n",
      "\u001b[1m180/181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - accuracy: 0.9116 - loss: 0.2511\n",
      "Epoch 42: val_loss did not improve from 1.04053\n",
      "\u001b[1m181/181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 69ms/step - accuracy: 0.9115 - loss: 0.2513 - val_accuracy: 0.6478 - val_loss: 1.4173\n",
      "Epoch 43/500\n",
      "\u001b[1m181/181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - accuracy: 0.9083 - loss: 0.2564\n",
      "Epoch 43: val_loss did not improve from 1.04053\n",
      "\u001b[1m181/181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 69ms/step - accuracy: 0.9083 - loss: 0.2564 - val_accuracy: 0.6983 - val_loss: 1.1860\n",
      "Epoch 44/500\n",
      "\u001b[1m180/181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - accuracy: 0.9206 - loss: 0.2304\n",
      "Epoch 44: val_loss did not improve from 1.04053\n",
      "\u001b[1m181/181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 66ms/step - accuracy: 0.9206 - loss: 0.2302 - val_accuracy: 0.7023 - val_loss: 1.2666\n",
      "Epoch 45/500\n",
      "\u001b[1m180/181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - accuracy: 0.9284 - loss: 0.2080\n",
      "Epoch 45: val_loss did not improve from 1.04053\n",
      "\u001b[1m181/181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 64ms/step - accuracy: 0.9284 - loss: 0.2081 - val_accuracy: 0.7073 - val_loss: 1.1902\n",
      "Epoch 46/500\n",
      "\u001b[1m180/181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - accuracy: 0.9361 - loss: 0.1846\n",
      "Epoch 46: val_loss did not improve from 1.04053\n",
      "\u001b[1m181/181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 66ms/step - accuracy: 0.9360 - loss: 0.1848 - val_accuracy: 0.6899 - val_loss: 1.2919\n",
      "Epoch 47/500\n",
      "\u001b[1m180/181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - accuracy: 0.9286 - loss: 0.2066\n",
      "Epoch 47: val_loss did not improve from 1.04053\n",
      "\u001b[1m181/181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 68ms/step - accuracy: 0.9285 - loss: 0.2067 - val_accuracy: 0.7042 - val_loss: 1.2241\n",
      "Epoch 48/500\n",
      "\u001b[1m180/181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - accuracy: 0.9362 - loss: 0.1852\n",
      "Epoch 48: val_loss did not improve from 1.04053\n",
      "\u001b[1m181/181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 67ms/step - accuracy: 0.9361 - loss: 0.1854 - val_accuracy: 0.6900 - val_loss: 1.3497\n",
      "Epoch 49/500\n",
      "\u001b[1m180/181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - accuracy: 0.9326 - loss: 0.2016\n",
      "Epoch 49: val_loss did not improve from 1.04053\n",
      "\u001b[1m181/181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 65ms/step - accuracy: 0.9326 - loss: 0.2017 - val_accuracy: 0.7084 - val_loss: 1.2381\n",
      "Epoch 50/500\n",
      "\u001b[1m180/181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - accuracy: 0.9393 - loss: 0.1769\n",
      "Epoch 50: val_loss did not improve from 1.04053\n",
      "\u001b[1m181/181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 63ms/step - accuracy: 0.9393 - loss: 0.1769 - val_accuracy: 0.7113 - val_loss: 1.2170\n",
      "Epoch 51/500\n",
      "\u001b[1m180/181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - accuracy: 0.9364 - loss: 0.1847\n",
      "Epoch 51: val_loss did not improve from 1.04053\n",
      "\u001b[1m181/181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 63ms/step - accuracy: 0.9364 - loss: 0.1847 - val_accuracy: 0.7269 - val_loss: 1.1591\n",
      "Epoch 52/500\n",
      "\u001b[1m180/181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - accuracy: 0.9395 - loss: 0.1759\n",
      "Epoch 52: val_loss did not improve from 1.04053\n",
      "\u001b[1m181/181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 63ms/step - accuracy: 0.9395 - loss: 0.1759 - val_accuracy: 0.7243 - val_loss: 1.2173\n",
      "Epoch 53/500\n",
      "\u001b[1m181/181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - accuracy: 0.9424 - loss: 0.1644\n",
      "Epoch 53: val_loss did not improve from 1.04053\n",
      "\u001b[1m181/181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 64ms/step - accuracy: 0.9424 - loss: 0.1644 - val_accuracy: 0.7312 - val_loss: 1.1796\n",
      "Epoch 54/500\n",
      "\u001b[1m180/181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - accuracy: 0.9583 - loss: 0.1224\n",
      "Epoch 54: val_loss did not improve from 1.04053\n",
      "\u001b[1m181/181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 64ms/step - accuracy: 0.9582 - loss: 0.1226 - val_accuracy: 0.7203 - val_loss: 1.3219\n",
      "Epoch 55/500\n",
      "\u001b[1m180/181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - accuracy: 0.9484 - loss: 0.1496\n",
      "Epoch 55: val_loss did not improve from 1.04053\n",
      "\u001b[1m181/181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 67ms/step - accuracy: 0.9484 - loss: 0.1497 - val_accuracy: 0.7136 - val_loss: 1.3110\n",
      "Epoch 56/500\n",
      "\u001b[1m180/181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - accuracy: 0.9534 - loss: 0.1369\n",
      "Epoch 56: val_loss did not improve from 1.04053\n",
      "\u001b[1m181/181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 63ms/step - accuracy: 0.9534 - loss: 0.1368 - val_accuracy: 0.7250 - val_loss: 1.3177\n",
      "Epoch 57/500\n",
      "\u001b[1m180/181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - accuracy: 0.9506 - loss: 0.1421\n",
      "Epoch 57: val_loss did not improve from 1.04053\n",
      "\u001b[1m181/181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 63ms/step - accuracy: 0.9505 - loss: 0.1422 - val_accuracy: 0.7021 - val_loss: 1.3160\n",
      "Epoch 58/500\n",
      "\u001b[1m180/181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - accuracy: 0.9532 - loss: 0.1406\n",
      "Epoch 58: val_loss did not improve from 1.04053\n",
      "\u001b[1m181/181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 64ms/step - accuracy: 0.9532 - loss: 0.1405 - val_accuracy: 0.7255 - val_loss: 1.2846\n",
      "Epoch 59/500\n",
      "\u001b[1m180/181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - accuracy: 0.9550 - loss: 0.1316\n",
      "Epoch 59: val_loss did not improve from 1.04053\n",
      "\u001b[1m181/181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 64ms/step - accuracy: 0.9550 - loss: 0.1316 - val_accuracy: 0.7229 - val_loss: 1.3525\n",
      "Epoch 60/500\n",
      "\u001b[1m180/181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - accuracy: 0.9562 - loss: 0.1331\n",
      "Epoch 60: val_loss did not improve from 1.04053\n",
      "\u001b[1m181/181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 64ms/step - accuracy: 0.9562 - loss: 0.1333 - val_accuracy: 0.7198 - val_loss: 1.3503\n",
      "Epoch 61/500\n",
      "\u001b[1m180/181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - accuracy: 0.9521 - loss: 0.1447\n",
      "Epoch 61: val_loss did not improve from 1.04053\n",
      "\u001b[1m181/181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 65ms/step - accuracy: 0.9521 - loss: 0.1447 - val_accuracy: 0.7127 - val_loss: 1.3353\n",
      "Epoch 62/500\n",
      "\u001b[1m180/181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - accuracy: 0.9565 - loss: 0.1315\n",
      "Epoch 62: val_loss did not improve from 1.04053\n",
      "\u001b[1m181/181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 64ms/step - accuracy: 0.9565 - loss: 0.1316 - val_accuracy: 0.7098 - val_loss: 1.3917\n",
      "Epoch 63/500\n",
      "\u001b[1m180/181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - accuracy: 0.9635 - loss: 0.1157\n",
      "Epoch 63: val_loss did not improve from 1.04053\n",
      "\u001b[1m181/181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 65ms/step - accuracy: 0.9634 - loss: 0.1158 - val_accuracy: 0.7465 - val_loss: 1.1732\n",
      "Epoch 64/500\n",
      "\u001b[1m180/181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - accuracy: 0.9642 - loss: 0.1060\n",
      "Epoch 64: val_loss did not improve from 1.04053\n",
      "\u001b[1m181/181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 65ms/step - accuracy: 0.9641 - loss: 0.1063 - val_accuracy: 0.7362 - val_loss: 1.1801\n",
      "Epoch 65/500\n",
      "\u001b[1m181/181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - accuracy: 0.9602 - loss: 0.1184\n",
      "Epoch 65: val_loss did not improve from 1.04053\n",
      "\u001b[1m181/181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 65ms/step - accuracy: 0.9602 - loss: 0.1184 - val_accuracy: 0.7236 - val_loss: 1.3016\n",
      "Epoch 66/500\n",
      "\u001b[1m180/181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - accuracy: 0.9542 - loss: 0.1451\n",
      "Epoch 66: val_loss did not improve from 1.04053\n",
      "\u001b[1m181/181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 66ms/step - accuracy: 0.9542 - loss: 0.1451 - val_accuracy: 0.7425 - val_loss: 1.1654\n",
      "Epoch 67/500\n",
      "\u001b[1m180/181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - accuracy: 0.9668 - loss: 0.1016\n",
      "Epoch 67: val_loss did not improve from 1.04053\n",
      "\u001b[1m181/181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 67ms/step - accuracy: 0.9668 - loss: 0.1016 - val_accuracy: 0.7388 - val_loss: 1.2379\n",
      "Epoch 68/500\n",
      "\u001b[1m181/181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - accuracy: 0.9660 - loss: 0.1014\n",
      "Epoch 68: val_loss did not improve from 1.04053\n",
      "\u001b[1m181/181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 70ms/step - accuracy: 0.9660 - loss: 0.1014 - val_accuracy: 0.7407 - val_loss: 1.2182\n",
      "Epoch 69/500\n",
      "\u001b[1m180/181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - accuracy: 0.9697 - loss: 0.0937\n",
      "Epoch 69: val_loss did not improve from 1.04053\n",
      "\u001b[1m181/181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 67ms/step - accuracy: 0.9696 - loss: 0.0938 - val_accuracy: 0.7366 - val_loss: 1.2934\n",
      "Epoch 70/500\n",
      "\u001b[1m180/181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - accuracy: 0.9646 - loss: 0.1070\n",
      "Epoch 70: val_loss did not improve from 1.04053\n",
      "\u001b[1m181/181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 65ms/step - accuracy: 0.9646 - loss: 0.1070 - val_accuracy: 0.7312 - val_loss: 1.3078\n",
      "Epoch 71/500\n",
      "\u001b[1m180/181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - accuracy: 0.9560 - loss: 0.1386\n",
      "Epoch 71: val_loss did not improve from 1.04053\n",
      "\u001b[1m181/181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 65ms/step - accuracy: 0.9559 - loss: 0.1388 - val_accuracy: 0.7182 - val_loss: 1.3764\n",
      "Epoch 72/500\n",
      "\u001b[1m180/181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - accuracy: 0.9687 - loss: 0.1006\n",
      "Epoch 72: val_loss did not improve from 1.04053\n",
      "\u001b[1m181/181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 65ms/step - accuracy: 0.9686 - loss: 0.1007 - val_accuracy: 0.7288 - val_loss: 1.2905\n",
      "Epoch 73/500\n",
      "\u001b[1m180/181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - accuracy: 0.9712 - loss: 0.0857\n",
      "Epoch 73: val_loss did not improve from 1.04053\n",
      "\u001b[1m181/181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 64ms/step - accuracy: 0.9712 - loss: 0.0858 - val_accuracy: 0.7042 - val_loss: 1.5127\n",
      "Epoch 73: early stopping\n",
      "Epoch 1/500\n",
      "\u001b[1m180/181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - accuracy: 0.1157 - loss: 2.5644\n",
      "Epoch 1: val_loss improved from inf to 2.32775, saving model to model/two_channel/model_alphabet_BETA.keras\n",
      "\u001b[1m181/181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 68ms/step - accuracy: 0.1157 - loss: 2.5629 - val_accuracy: 0.1000 - val_loss: 2.3277\n",
      "Epoch 2/500\n",
      "\u001b[1m180/181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 0.1379 - loss: 2.3029\n",
      "Epoch 2: val_loss did not improve from 2.32775\n",
      "\u001b[1m181/181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 61ms/step - accuracy: 0.1379 - loss: 2.3028 - val_accuracy: 0.1064 - val_loss: 2.3281\n",
      "Epoch 3/500\n",
      "\u001b[1m180/181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 0.1577 - loss: 2.2402\n",
      "Epoch 3: val_loss improved from 2.32775 to 2.30631, saving model to model/two_channel/model_alphabet_BETA.keras\n",
      "\u001b[1m181/181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 62ms/step - accuracy: 0.1577 - loss: 2.2401 - val_accuracy: 0.1049 - val_loss: 2.3063\n",
      "Epoch 4/500\n",
      "\u001b[1m180/181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 0.1732 - loss: 2.1960\n",
      "Epoch 4: val_loss did not improve from 2.30631\n",
      "\u001b[1m181/181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 61ms/step - accuracy: 0.1732 - loss: 2.1960 - val_accuracy: 0.1494 - val_loss: 2.3863\n",
      "Epoch 5/500\n",
      "\u001b[1m180/181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 0.2035 - loss: 2.1356\n",
      "Epoch 5: val_loss improved from 2.30631 to 2.15330, saving model to model/two_channel/model_alphabet_BETA.keras\n",
      "\u001b[1m181/181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 60ms/step - accuracy: 0.2035 - loss: 2.1356 - val_accuracy: 0.1869 - val_loss: 2.1533\n",
      "Epoch 6/500\n",
      "\u001b[1m180/181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 0.2238 - loss: 2.0829\n",
      "Epoch 6: val_loss improved from 2.15330 to 2.10036, saving model to model/two_channel/model_alphabet_BETA.keras\n",
      "\u001b[1m181/181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 58ms/step - accuracy: 0.2239 - loss: 2.0828 - val_accuracy: 0.2060 - val_loss: 2.1004\n",
      "Epoch 7/500\n",
      "\u001b[1m180/181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - accuracy: 0.2486 - loss: 2.0198\n",
      "Epoch 7: val_loss improved from 2.10036 to 2.09481, saving model to model/two_channel/model_alphabet_BETA.keras\n",
      "\u001b[1m181/181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 57ms/step - accuracy: 0.2486 - loss: 2.0199 - val_accuracy: 0.2184 - val_loss: 2.0948\n",
      "Epoch 8/500\n",
      "\u001b[1m180/181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - accuracy: 0.2725 - loss: 1.9649\n",
      "Epoch 8: val_loss did not improve from 2.09481\n",
      "\u001b[1m181/181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 58ms/step - accuracy: 0.2725 - loss: 1.9649 - val_accuracy: 0.2099 - val_loss: 2.1436\n",
      "Epoch 9/500\n",
      "\u001b[1m180/181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - accuracy: 0.2958 - loss: 1.9202\n",
      "Epoch 9: val_loss improved from 2.09481 to 2.00906, saving model to model/two_channel/model_alphabet_BETA.keras\n",
      "\u001b[1m181/181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 58ms/step - accuracy: 0.2958 - loss: 1.9201 - val_accuracy: 0.2631 - val_loss: 2.0091\n",
      "Epoch 10/500\n",
      "\u001b[1m180/181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - accuracy: 0.3258 - loss: 1.8453\n",
      "Epoch 10: val_loss did not improve from 2.00906\n",
      "\u001b[1m181/181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 58ms/step - accuracy: 0.3258 - loss: 1.8454 - val_accuracy: 0.2658 - val_loss: 2.0345\n",
      "Epoch 11/500\n",
      "\u001b[1m180/181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 0.3572 - loss: 1.7701\n",
      "Epoch 11: val_loss improved from 2.00906 to 1.99216, saving model to model/two_channel/model_alphabet_BETA.keras\n",
      "\u001b[1m181/181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 59ms/step - accuracy: 0.3571 - loss: 1.7702 - val_accuracy: 0.2780 - val_loss: 1.9922\n",
      "Epoch 12/500\n",
      "\u001b[1m181/181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 0.3783 - loss: 1.7075\n",
      "Epoch 12: val_loss improved from 1.99216 to 1.91634, saving model to model/two_channel/model_alphabet_BETA.keras\n",
      "\u001b[1m181/181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 59ms/step - accuracy: 0.3783 - loss: 1.7075 - val_accuracy: 0.3055 - val_loss: 1.9163\n",
      "Epoch 13/500\n",
      "\u001b[1m180/181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 0.4101 - loss: 1.6398\n",
      "Epoch 13: val_loss did not improve from 1.91634\n",
      "\u001b[1m181/181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 59ms/step - accuracy: 0.4101 - loss: 1.6399 - val_accuracy: 0.3131 - val_loss: 1.9354\n",
      "Epoch 14/500\n",
      "\u001b[1m180/181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 0.4315 - loss: 1.5819\n",
      "Epoch 14: val_loss improved from 1.91634 to 1.84195, saving model to model/two_channel/model_alphabet_BETA.keras\n",
      "\u001b[1m181/181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 59ms/step - accuracy: 0.4314 - loss: 1.5821 - val_accuracy: 0.3314 - val_loss: 1.8419\n",
      "Epoch 15/500\n",
      "\u001b[1m180/181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 0.4623 - loss: 1.4943\n",
      "Epoch 15: val_loss improved from 1.84195 to 1.81939, saving model to model/two_channel/model_alphabet_BETA.keras\n",
      "\u001b[1m181/181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 61ms/step - accuracy: 0.4622 - loss: 1.4944 - val_accuracy: 0.3489 - val_loss: 1.8194\n",
      "Epoch 16/500\n",
      "\u001b[1m180/181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 0.4889 - loss: 1.4267\n",
      "Epoch 16: val_loss did not improve from 1.81939\n",
      "\u001b[1m181/181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 59ms/step - accuracy: 0.4888 - loss: 1.4269 - val_accuracy: 0.3339 - val_loss: 1.9725\n",
      "Epoch 17/500\n",
      "\u001b[1m180/181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 0.5206 - loss: 1.3512\n",
      "Epoch 17: val_loss improved from 1.81939 to 1.79349, saving model to model/two_channel/model_alphabet_BETA.keras\n",
      "\u001b[1m181/181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 58ms/step - accuracy: 0.5205 - loss: 1.3513 - val_accuracy: 0.3754 - val_loss: 1.7935\n",
      "Epoch 18/500\n",
      "\u001b[1m180/181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 0.5569 - loss: 1.2598\n",
      "Epoch 18: val_loss improved from 1.79349 to 1.71390, saving model to model/two_channel/model_alphabet_BETA.keras\n",
      "\u001b[1m181/181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 59ms/step - accuracy: 0.5568 - loss: 1.2601 - val_accuracy: 0.4022 - val_loss: 1.7139\n",
      "Epoch 19/500\n",
      "\u001b[1m180/181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.5875 - loss: 1.1728\n",
      "Epoch 19: val_loss did not improve from 1.71390\n",
      "\u001b[1m181/181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 59ms/step - accuracy: 0.5874 - loss: 1.1730 - val_accuracy: 0.4039 - val_loss: 1.8654\n",
      "Epoch 20/500\n",
      "\u001b[1m180/181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 0.6103 - loss: 1.0998\n",
      "Epoch 20: val_loss did not improve from 1.71390\n",
      "\u001b[1m181/181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 60ms/step - accuracy: 0.6103 - loss: 1.0999 - val_accuracy: 0.4271 - val_loss: 1.8431\n",
      "Epoch 21/500\n",
      "\u001b[1m180/181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 0.6506 - loss: 0.9958\n",
      "Epoch 21: val_loss improved from 1.71390 to 1.66726, saving model to model/two_channel/model_alphabet_BETA.keras\n",
      "\u001b[1m181/181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 62ms/step - accuracy: 0.6504 - loss: 0.9962 - val_accuracy: 0.4612 - val_loss: 1.6673\n",
      "Epoch 22/500\n",
      "\u001b[1m180/181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 0.6788 - loss: 0.9302\n",
      "Epoch 22: val_loss improved from 1.66726 to 1.65158, saving model to model/two_channel/model_alphabet_BETA.keras\n",
      "\u001b[1m181/181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 60ms/step - accuracy: 0.6787 - loss: 0.9304 - val_accuracy: 0.4635 - val_loss: 1.6516\n",
      "Epoch 23/500\n",
      "\u001b[1m180/181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.7071 - loss: 0.8329\n",
      "Epoch 23: val_loss improved from 1.65158 to 1.63371, saving model to model/two_channel/model_alphabet_BETA.keras\n",
      "\u001b[1m181/181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 60ms/step - accuracy: 0.7070 - loss: 0.8332 - val_accuracy: 0.4875 - val_loss: 1.6337\n",
      "Epoch 24/500\n",
      "\u001b[1m180/181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.7332 - loss: 0.7787\n",
      "Epoch 24: val_loss improved from 1.63371 to 1.62256, saving model to model/two_channel/model_alphabet_BETA.keras\n",
      "\u001b[1m181/181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 60ms/step - accuracy: 0.7331 - loss: 0.7788 - val_accuracy: 0.5067 - val_loss: 1.6226\n",
      "Epoch 25/500\n",
      "\u001b[1m180/181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - accuracy: 0.7607 - loss: 0.7005\n",
      "Epoch 25: val_loss did not improve from 1.62256\n",
      "\u001b[1m181/181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 69ms/step - accuracy: 0.7607 - loss: 0.7007 - val_accuracy: 0.5016 - val_loss: 1.7861\n",
      "Epoch 26/500\n",
      "\u001b[1m180/181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.7863 - loss: 0.6166\n",
      "Epoch 26: val_loss did not improve from 1.62256\n",
      "\u001b[1m181/181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 60ms/step - accuracy: 0.7862 - loss: 0.6169 - val_accuracy: 0.5343 - val_loss: 1.6408\n",
      "Epoch 27/500\n",
      "\u001b[1m180/181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - accuracy: 0.8045 - loss: 0.5799\n",
      "Epoch 27: val_loss did not improve from 1.62256\n",
      "\u001b[1m181/181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 65ms/step - accuracy: 0.8044 - loss: 0.5800 - val_accuracy: 0.5415 - val_loss: 1.6359\n",
      "Epoch 28/500\n",
      "\u001b[1m180/181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - accuracy: 0.8286 - loss: 0.5059\n",
      "Epoch 28: val_loss did not improve from 1.62256\n",
      "\u001b[1m181/181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 64ms/step - accuracy: 0.8285 - loss: 0.5062 - val_accuracy: 0.5386 - val_loss: 1.7233\n",
      "Epoch 29/500\n",
      "\u001b[1m180/181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 0.8443 - loss: 0.4658\n",
      "Epoch 29: val_loss did not improve from 1.62256\n",
      "\u001b[1m181/181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 60ms/step - accuracy: 0.8442 - loss: 0.4659 - val_accuracy: 0.5620 - val_loss: 1.7297\n",
      "Epoch 30/500\n",
      "\u001b[1m180/181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.8561 - loss: 0.4283\n",
      "Epoch 30: val_loss did not improve from 1.62256\n",
      "\u001b[1m181/181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 59ms/step - accuracy: 0.8561 - loss: 0.4284 - val_accuracy: 0.5845 - val_loss: 1.6715\n",
      "Epoch 31/500\n",
      "\u001b[1m180/181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.8877 - loss: 0.3326\n",
      "Epoch 31: val_loss did not improve from 1.62256\n",
      "\u001b[1m181/181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 60ms/step - accuracy: 0.8875 - loss: 0.3331 - val_accuracy: 0.5862 - val_loss: 1.6467\n",
      "Epoch 32/500\n",
      "\u001b[1m180/181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 0.8847 - loss: 0.3431\n",
      "Epoch 32: val_loss did not improve from 1.62256\n",
      "\u001b[1m181/181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 60ms/step - accuracy: 0.8847 - loss: 0.3432 - val_accuracy: 0.5912 - val_loss: 1.6788\n",
      "Epoch 33/500\n",
      "\u001b[1m180/181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 0.8945 - loss: 0.3184\n",
      "Epoch 33: val_loss did not improve from 1.62256\n",
      "\u001b[1m181/181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 61ms/step - accuracy: 0.8945 - loss: 0.3185 - val_accuracy: 0.5777 - val_loss: 1.7976\n",
      "Epoch 34/500\n",
      "\u001b[1m180/181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 0.9109 - loss: 0.2685\n",
      "Epoch 34: val_loss did not improve from 1.62256\n",
      "\u001b[1m181/181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 63ms/step - accuracy: 0.9108 - loss: 0.2688 - val_accuracy: 0.6120 - val_loss: 1.7479\n",
      "Epoch 35/500\n",
      "\u001b[1m180/181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 0.9079 - loss: 0.2748\n",
      "Epoch 35: val_loss did not improve from 1.62256\n",
      "\u001b[1m181/181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 62ms/step - accuracy: 0.9079 - loss: 0.2749 - val_accuracy: 0.6033 - val_loss: 1.7864\n",
      "Epoch 36/500\n",
      "\u001b[1m180/181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 0.9209 - loss: 0.2512\n",
      "Epoch 36: val_loss did not improve from 1.62256\n",
      "\u001b[1m181/181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 62ms/step - accuracy: 0.9208 - loss: 0.2513 - val_accuracy: 0.6111 - val_loss: 1.7181\n",
      "Epoch 37/500\n",
      "\u001b[1m180/181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 0.9212 - loss: 0.2406\n",
      "Epoch 37: val_loss did not improve from 1.62256\n",
      "\u001b[1m181/181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 62ms/step - accuracy: 0.9211 - loss: 0.2406 - val_accuracy: 0.6260 - val_loss: 1.7474\n",
      "Epoch 38/500\n",
      "\u001b[1m180/181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 0.9367 - loss: 0.1923\n",
      "Epoch 38: val_loss did not improve from 1.62256\n",
      "\u001b[1m181/181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 63ms/step - accuracy: 0.9366 - loss: 0.1925 - val_accuracy: 0.6191 - val_loss: 1.7253\n",
      "Epoch 39/500\n",
      "\u001b[1m180/181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 0.9346 - loss: 0.1975\n",
      "Epoch 39: val_loss did not improve from 1.62256\n",
      "\u001b[1m181/181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 61ms/step - accuracy: 0.9345 - loss: 0.1977 - val_accuracy: 0.6272 - val_loss: 1.6478\n",
      "Epoch 40/500\n",
      "\u001b[1m180/181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 0.9385 - loss: 0.1916\n",
      "Epoch 40: val_loss did not improve from 1.62256\n",
      "\u001b[1m181/181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 62ms/step - accuracy: 0.9385 - loss: 0.1918 - val_accuracy: 0.6198 - val_loss: 1.8246\n",
      "Epoch 41/500\n",
      "\u001b[1m180/181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 0.9375 - loss: 0.1941\n",
      "Epoch 41: val_loss did not improve from 1.62256\n",
      "\u001b[1m181/181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 62ms/step - accuracy: 0.9375 - loss: 0.1941 - val_accuracy: 0.6329 - val_loss: 1.7453\n",
      "Epoch 42/500\n",
      "\u001b[1m180/181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 0.9479 - loss: 0.1637\n",
      "Epoch 42: val_loss did not improve from 1.62256\n",
      "\u001b[1m181/181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 62ms/step - accuracy: 0.9478 - loss: 0.1640 - val_accuracy: 0.6286 - val_loss: 1.6993\n",
      "Epoch 43/500\n",
      "\u001b[1m180/181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - accuracy: 0.9424 - loss: 0.1654\n",
      "Epoch 43: val_loss did not improve from 1.62256\n",
      "\u001b[1m181/181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 64ms/step - accuracy: 0.9424 - loss: 0.1654 - val_accuracy: 0.6310 - val_loss: 1.8094\n",
      "Epoch 44/500\n",
      "\u001b[1m180/181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - accuracy: 0.9498 - loss: 0.1513\n",
      "Epoch 44: val_loss did not improve from 1.62256\n",
      "\u001b[1m181/181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 64ms/step - accuracy: 0.9498 - loss: 0.1514 - val_accuracy: 0.6305 - val_loss: 1.8801\n",
      "Epoch 45/500\n",
      "\u001b[1m180/181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 0.9532 - loss: 0.1468\n",
      "Epoch 45: val_loss did not improve from 1.62256\n",
      "\u001b[1m181/181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 63ms/step - accuracy: 0.9532 - loss: 0.1469 - val_accuracy: 0.6312 - val_loss: 1.8007\n",
      "Epoch 46/500\n",
      "\u001b[1m180/181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 0.9535 - loss: 0.1406\n",
      "Epoch 46: val_loss did not improve from 1.62256\n",
      "\u001b[1m181/181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 63ms/step - accuracy: 0.9535 - loss: 0.1406 - val_accuracy: 0.6400 - val_loss: 1.8689\n",
      "Epoch 47/500\n",
      "\u001b[1m180/181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 0.9534 - loss: 0.1443\n",
      "Epoch 47: val_loss did not improve from 1.62256\n",
      "\u001b[1m181/181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 63ms/step - accuracy: 0.9534 - loss: 0.1443 - val_accuracy: 0.6506 - val_loss: 1.7586\n",
      "Epoch 48/500\n",
      "\u001b[1m180/181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 0.9564 - loss: 0.1382\n",
      "Epoch 48: val_loss did not improve from 1.62256\n",
      "\u001b[1m181/181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 62ms/step - accuracy: 0.9564 - loss: 0.1382 - val_accuracy: 0.6509 - val_loss: 1.7965\n",
      "Epoch 49/500\n",
      "\u001b[1m180/181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 0.9674 - loss: 0.1017\n",
      "Epoch 49: val_loss did not improve from 1.62256\n",
      "\u001b[1m181/181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 62ms/step - accuracy: 0.9672 - loss: 0.1021 - val_accuracy: 0.6367 - val_loss: 1.9244\n",
      "Epoch 50/500\n",
      "\u001b[1m180/181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 0.9534 - loss: 0.1514\n",
      "Epoch 50: val_loss did not improve from 1.62256\n",
      "\u001b[1m181/181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 62ms/step - accuracy: 0.9534 - loss: 0.1514 - val_accuracy: 0.6641 - val_loss: 1.7610\n",
      "Epoch 51/500\n",
      "\u001b[1m180/181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 0.9567 - loss: 0.1330\n",
      "Epoch 51: val_loss did not improve from 1.62256\n",
      "\u001b[1m181/181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 61ms/step - accuracy: 0.9567 - loss: 0.1332 - val_accuracy: 0.6466 - val_loss: 1.7415\n",
      "Epoch 52/500\n",
      "\u001b[1m180/181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 0.9613 - loss: 0.1200\n",
      "Epoch 52: val_loss did not improve from 1.62256\n",
      "\u001b[1m181/181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 63ms/step - accuracy: 0.9613 - loss: 0.1200 - val_accuracy: 0.6464 - val_loss: 1.8816\n",
      "Epoch 53/500\n",
      "\u001b[1m180/181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 0.9615 - loss: 0.1177\n",
      "Epoch 53: val_loss did not improve from 1.62256\n",
      "\u001b[1m181/181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 60ms/step - accuracy: 0.9615 - loss: 0.1177 - val_accuracy: 0.6734 - val_loss: 1.7126\n",
      "Epoch 54/500\n",
      "\u001b[1m181/181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 0.9711 - loss: 0.0904\n",
      "Epoch 54: val_loss did not improve from 1.62256\n",
      "\u001b[1m181/181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 61ms/step - accuracy: 0.9711 - loss: 0.0905 - val_accuracy: 0.6523 - val_loss: 1.7688\n",
      "Epoch 55/500\n",
      "\u001b[1m180/181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 0.9595 - loss: 0.1188\n",
      "Epoch 55: val_loss did not improve from 1.62256\n",
      "\u001b[1m181/181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 61ms/step - accuracy: 0.9594 - loss: 0.1190 - val_accuracy: 0.6426 - val_loss: 1.8462\n",
      "Epoch 56/500\n",
      "\u001b[1m180/181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.9651 - loss: 0.1096\n",
      "Epoch 56: val_loss did not improve from 1.62256\n",
      "\u001b[1m181/181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 60ms/step - accuracy: 0.9650 - loss: 0.1098 - val_accuracy: 0.6575 - val_loss: 1.7617\n",
      "Epoch 57/500\n",
      "\u001b[1m180/181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 0.9629 - loss: 0.1133\n",
      "Epoch 57: val_loss did not improve from 1.62256\n",
      "\u001b[1m181/181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 61ms/step - accuracy: 0.9629 - loss: 0.1133 - val_accuracy: 0.6601 - val_loss: 1.7632\n",
      "Epoch 58/500\n",
      "\u001b[1m180/181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 0.9652 - loss: 0.1176\n",
      "Epoch 58: val_loss did not improve from 1.62256\n",
      "\u001b[1m181/181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 62ms/step - accuracy: 0.9652 - loss: 0.1177 - val_accuracy: 0.6511 - val_loss: 1.8004\n",
      "Epoch 59/500\n",
      "\u001b[1m180/181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 0.9642 - loss: 0.1109\n",
      "Epoch 59: val_loss did not improve from 1.62256\n",
      "\u001b[1m181/181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 58ms/step - accuracy: 0.9642 - loss: 0.1110 - val_accuracy: 0.6753 - val_loss: 1.6707\n",
      "Epoch 60/500\n",
      "\u001b[1m180/181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.9720 - loss: 0.0904\n",
      "Epoch 60: val_loss did not improve from 1.62256\n",
      "\u001b[1m181/181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 59ms/step - accuracy: 0.9719 - loss: 0.0905 - val_accuracy: 0.6682 - val_loss: 1.7104\n",
      "Epoch 61/500\n",
      "\u001b[1m180/181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - accuracy: 0.9676 - loss: 0.1040\n",
      "Epoch 61: val_loss did not improve from 1.62256\n",
      "\u001b[1m181/181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 58ms/step - accuracy: 0.9676 - loss: 0.1041 - val_accuracy: 0.6655 - val_loss: 1.8511\n",
      "Epoch 62/500\n",
      "\u001b[1m180/181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - accuracy: 0.9659 - loss: 0.1038\n",
      "Epoch 62: val_loss did not improve from 1.62256\n",
      "\u001b[1m181/181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 57ms/step - accuracy: 0.9659 - loss: 0.1039 - val_accuracy: 0.6765 - val_loss: 1.6860\n",
      "Epoch 63/500\n",
      "\u001b[1m180/181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 0.9729 - loss: 0.0845\n",
      "Epoch 63: val_loss did not improve from 1.62256\n",
      "\u001b[1m181/181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 60ms/step - accuracy: 0.9728 - loss: 0.0845 - val_accuracy: 0.6810 - val_loss: 1.6643\n",
      "Epoch 64/500\n",
      "\u001b[1m180/181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.9707 - loss: 0.0957\n",
      "Epoch 64: val_loss did not improve from 1.62256\n",
      "\u001b[1m181/181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 60ms/step - accuracy: 0.9707 - loss: 0.0958 - val_accuracy: 0.6577 - val_loss: 1.8274\n",
      "Epoch 65/500\n",
      "\u001b[1m180/181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 0.9689 - loss: 0.1004\n",
      "Epoch 65: val_loss did not improve from 1.62256\n",
      "\u001b[1m181/181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 58ms/step - accuracy: 0.9689 - loss: 0.1003 - val_accuracy: 0.6732 - val_loss: 1.7807\n",
      "Epoch 66/500\n",
      "\u001b[1m180/181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - accuracy: 0.9705 - loss: 0.0919\n",
      "Epoch 66: val_loss did not improve from 1.62256\n",
      "\u001b[1m181/181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 57ms/step - accuracy: 0.9705 - loss: 0.0920 - val_accuracy: 0.6739 - val_loss: 1.8016\n",
      "Epoch 67/500\n",
      "\u001b[1m180/181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 0.9703 - loss: 0.0982\n",
      "Epoch 67: val_loss did not improve from 1.62256\n",
      "\u001b[1m181/181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 58ms/step - accuracy: 0.9703 - loss: 0.0982 - val_accuracy: 0.6681 - val_loss: 1.8249\n",
      "Epoch 68/500\n",
      "\u001b[1m181/181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - accuracy: 0.9731 - loss: 0.0907\n",
      "Epoch 68: val_loss did not improve from 1.62256\n",
      "\u001b[1m181/181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 58ms/step - accuracy: 0.9730 - loss: 0.0907 - val_accuracy: 0.6798 - val_loss: 1.6566\n",
      "Epoch 69/500\n",
      "\u001b[1m181/181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 0.9729 - loss: 0.0855\n",
      "Epoch 69: val_loss did not improve from 1.62256\n",
      "\u001b[1m181/181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 58ms/step - accuracy: 0.9729 - loss: 0.0855 - val_accuracy: 0.6774 - val_loss: 1.7653\n",
      "Epoch 70/500\n",
      "\u001b[1m180/181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - accuracy: 0.9690 - loss: 0.0970\n",
      "Epoch 70: val_loss did not improve from 1.62256\n",
      "\u001b[1m181/181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 58ms/step - accuracy: 0.9690 - loss: 0.0970 - val_accuracy: 0.6712 - val_loss: 1.8038\n",
      "Epoch 71/500\n",
      "\u001b[1m180/181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 0.9722 - loss: 0.0920\n",
      "Epoch 71: val_loss did not improve from 1.62256\n",
      "\u001b[1m181/181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 58ms/step - accuracy: 0.9722 - loss: 0.0920 - val_accuracy: 0.6667 - val_loss: 1.9141\n",
      "Epoch 72/500\n",
      "\u001b[1m180/181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 0.9725 - loss: 0.0860\n",
      "Epoch 72: val_loss did not improve from 1.62256\n",
      "\u001b[1m181/181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 58ms/step - accuracy: 0.9725 - loss: 0.0860 - val_accuracy: 0.6983 - val_loss: 1.7220\n",
      "Epoch 73/500\n",
      "\u001b[1m180/181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 0.9796 - loss: 0.0663\n",
      "Epoch 73: val_loss did not improve from 1.62256\n",
      "\u001b[1m181/181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 59ms/step - accuracy: 0.9796 - loss: 0.0664 - val_accuracy: 0.6781 - val_loss: 1.9042\n",
      "Epoch 74/500\n",
      "\u001b[1m180/181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 0.9710 - loss: 0.0918\n",
      "Epoch 74: val_loss did not improve from 1.62256\n",
      "\u001b[1m181/181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 59ms/step - accuracy: 0.9710 - loss: 0.0918 - val_accuracy: 0.6771 - val_loss: 1.7152\n",
      "Epoch 75/500\n",
      "\u001b[1m180/181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 0.9744 - loss: 0.0861\n",
      "Epoch 75: val_loss did not improve from 1.62256\n",
      "\u001b[1m181/181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 59ms/step - accuracy: 0.9744 - loss: 0.0861 - val_accuracy: 0.6890 - val_loss: 1.6988\n",
      "Epoch 76/500\n",
      "\u001b[1m180/181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.9752 - loss: 0.0789\n",
      "Epoch 76: val_loss did not improve from 1.62256\n",
      "\u001b[1m181/181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 59ms/step - accuracy: 0.9752 - loss: 0.0790 - val_accuracy: 0.6838 - val_loss: 1.7861\n",
      "Epoch 77/500\n",
      "\u001b[1m180/181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - accuracy: 0.9686 - loss: 0.1010\n",
      "Epoch 77: val_loss did not improve from 1.62256\n",
      "\u001b[1m181/181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 67ms/step - accuracy: 0.9686 - loss: 0.1010 - val_accuracy: 0.6829 - val_loss: 1.7678\n",
      "Epoch 78/500\n",
      "\u001b[1m180/181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - accuracy: 0.9747 - loss: 0.0760\n",
      "Epoch 78: val_loss did not improve from 1.62256\n",
      "\u001b[1m181/181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 64ms/step - accuracy: 0.9747 - loss: 0.0760 - val_accuracy: 0.6771 - val_loss: 1.6972\n",
      "Epoch 79/500\n",
      "\u001b[1m180/181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 0.9776 - loss: 0.0728\n",
      "Epoch 79: val_loss did not improve from 1.62256\n",
      "\u001b[1m181/181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 60ms/step - accuracy: 0.9776 - loss: 0.0728 - val_accuracy: 0.6937 - val_loss: 1.7164\n",
      "Epoch 80/500\n",
      "\u001b[1m180/181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 0.9758 - loss: 0.0728\n",
      "Epoch 80: val_loss did not improve from 1.62256\n",
      "\u001b[1m181/181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 60ms/step - accuracy: 0.9758 - loss: 0.0729 - val_accuracy: 0.6843 - val_loss: 1.7517\n",
      "Epoch 81/500\n",
      "\u001b[1m180/181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.9764 - loss: 0.0734\n",
      "Epoch 81: val_loss did not improve from 1.62256\n",
      "\u001b[1m181/181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 59ms/step - accuracy: 0.9764 - loss: 0.0735 - val_accuracy: 0.6693 - val_loss: 1.9487\n",
      "Epoch 82/500\n",
      "\u001b[1m180/181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.9773 - loss: 0.0750\n",
      "Epoch 82: val_loss did not improve from 1.62256\n",
      "\u001b[1m181/181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 60ms/step - accuracy: 0.9773 - loss: 0.0750 - val_accuracy: 0.6843 - val_loss: 1.6939\n",
      "Epoch 82: early stopping\n",
      "Epoch 1/500\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 120ms/step - accuracy: 0.1012 - loss: 2.2939 - val_accuracy: 0.1965 - val_loss: 2.2112\n",
      "Epoch 2/500\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 106ms/step - accuracy: 0.2497 - loss: 2.1827 - val_accuracy: 0.2623 - val_loss: 2.1619\n",
      "Epoch 3/500\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 107ms/step - accuracy: 0.3070 - loss: 2.1311 - val_accuracy: 0.3045 - val_loss: 2.1305\n",
      "Epoch 4/500\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 106ms/step - accuracy: 0.3679 - loss: 2.0761 - val_accuracy: 0.3384 - val_loss: 2.0729\n",
      "Epoch 5/500\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 111ms/step - accuracy: 0.3997 - loss: 2.0251 - val_accuracy: 0.3426 - val_loss: 2.0496\n",
      "Epoch 6/500\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 108ms/step - accuracy: 0.4183 - loss: 1.9802 - val_accuracy: 0.3439 - val_loss: 2.0171\n",
      "Epoch 7/500\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 106ms/step - accuracy: 0.4645 - loss: 1.9205 - val_accuracy: 0.3903 - val_loss: 1.9748\n",
      "Epoch 8/500\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 106ms/step - accuracy: 0.4604 - loss: 1.8862 - val_accuracy: 0.3689 - val_loss: 1.9503\n",
      "Epoch 9/500\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 106ms/step - accuracy: 0.4451 - loss: 1.8554 - val_accuracy: 0.4360 - val_loss: 1.8952\n",
      "Epoch 10/500\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 106ms/step - accuracy: 0.5343 - loss: 1.7988 - val_accuracy: 0.4775 - val_loss: 1.8516\n",
      "Epoch 11/500\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 106ms/step - accuracy: 0.5983 - loss: 1.7296 - val_accuracy: 0.4685 - val_loss: 1.8524\n",
      "Epoch 12/500\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 105ms/step - accuracy: 0.5866 - loss: 1.7054 - val_accuracy: 0.4450 - val_loss: 1.8653\n",
      "Epoch 13/500\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 105ms/step - accuracy: 0.5758 - loss: 1.6718 - val_accuracy: 0.4519 - val_loss: 1.7997\n",
      "Epoch 14/500\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 106ms/step - accuracy: 0.5852 - loss: 1.6105 - val_accuracy: 0.4464 - val_loss: 1.7662\n",
      "Epoch 15/500\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 105ms/step - accuracy: 0.6034 - loss: 1.5740 - val_accuracy: 0.4263 - val_loss: 1.7960\n",
      "Epoch 16/500\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 107ms/step - accuracy: 0.5944 - loss: 1.5412 - val_accuracy: 0.4554 - val_loss: 1.7628\n",
      "Epoch 17/500\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 107ms/step - accuracy: 0.6111 - loss: 1.4976 - val_accuracy: 0.4803 - val_loss: 1.6935\n",
      "Epoch 18/500\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 105ms/step - accuracy: 0.6202 - loss: 1.4617 - val_accuracy: 0.4602 - val_loss: 1.7069\n",
      "Epoch 19/500\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 106ms/step - accuracy: 0.6192 - loss: 1.4150 - val_accuracy: 0.4754 - val_loss: 1.6533\n",
      "Epoch 20/500\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 105ms/step - accuracy: 0.6364 - loss: 1.3693 - val_accuracy: 0.4685 - val_loss: 1.6634\n",
      "Epoch 21/500\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 106ms/step - accuracy: 0.6252 - loss: 1.3725 - val_accuracy: 0.4692 - val_loss: 1.6452\n",
      "Epoch 22/500\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 107ms/step - accuracy: 0.6575 - loss: 1.2873 - val_accuracy: 0.4574 - val_loss: 1.6618\n",
      "Epoch 23/500\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 108ms/step - accuracy: 0.6440 - loss: 1.3037 - val_accuracy: 0.4484 - val_loss: 1.6633\n",
      "Epoch 24/500\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 109ms/step - accuracy: 0.6559 - loss: 1.2361 - val_accuracy: 0.4768 - val_loss: 1.6182\n",
      "Epoch 25/500\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 107ms/step - accuracy: 0.6629 - loss: 1.2086 - val_accuracy: 0.4747 - val_loss: 1.6155\n",
      "Epoch 26/500\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 106ms/step - accuracy: 0.6662 - loss: 1.1557 - val_accuracy: 0.4740 - val_loss: 1.5927\n",
      "Epoch 27/500\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 107ms/step - accuracy: 0.6857 - loss: 1.1264 - val_accuracy: 0.4941 - val_loss: 1.5536\n",
      "Epoch 28/500\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 107ms/step - accuracy: 0.6824 - loss: 1.1120 - val_accuracy: 0.4630 - val_loss: 1.6345\n",
      "Epoch 29/500\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 106ms/step - accuracy: 0.6718 - loss: 1.1083 - val_accuracy: 0.4837 - val_loss: 1.5653\n",
      "Epoch 30/500\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 106ms/step - accuracy: 0.6815 - loss: 1.1011 - val_accuracy: 0.4574 - val_loss: 1.6428\n",
      "Epoch 31/500\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 106ms/step - accuracy: 0.6719 - loss: 1.0989 - val_accuracy: 0.4872 - val_loss: 1.5978\n",
      "Epoch 32/500\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 107ms/step - accuracy: 0.6887 - loss: 1.0544 - val_accuracy: 0.4526 - val_loss: 1.6882\n",
      "Epoch 33/500\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 108ms/step - accuracy: 0.7014 - loss: 1.0157 - val_accuracy: 0.4740 - val_loss: 1.5357\n",
      "Epoch 34/500\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 107ms/step - accuracy: 0.7102 - loss: 0.9575 - val_accuracy: 0.4561 - val_loss: 1.6015\n",
      "Epoch 35/500\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 106ms/step - accuracy: 0.6821 - loss: 1.0344 - val_accuracy: 0.4754 - val_loss: 1.6219\n",
      "Epoch 36/500\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 106ms/step - accuracy: 0.7158 - loss: 0.9370 - val_accuracy: 0.4588 - val_loss: 1.6460\n",
      "Epoch 37/500\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 107ms/step - accuracy: 0.7183 - loss: 0.9078 - val_accuracy: 0.4602 - val_loss: 1.6036\n",
      "Epoch 37: early stopping\n",
      "Restoring model weights from the end of the best epoch: 27.\n",
      "\u001b[1m226/226\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step\n",
      "Attention-Based Late Fusion Accuracy: 66.53%\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAW4AAAEWCAYAAABG030jAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8hTgPZAAAACXBIWXMAAAsTAAALEwEAmpwYAABjeElEQVR4nO2dd3wVxdeHn5NGb6GEXgIBpIjSpIsUFQTpRVAsKKJIC71IEUFR7P5EpQkivRdBkA7SQREBFWnSElooSSBt3j92Ey6Ynt0NN+88+ewne7fMmdnde+7smfIVpRQajUajcR880jsDGo1Go0kZ2nFrNBqNm6Edt0aj0bgZ2nFrNBqNm6Edt0aj0bgZ2nFrNBqNm6EddwoQkSwislJErovIwjSk01VE1lmZt/RARNaIyIvpnQ+nEJE/RKRheufjQUVEhovI1PTOx/8HMqTjFpEuIrJPRG6JyAXTwdSzIOn2gB+QVynVIbWJKKV+UEo9aUF+7kFEGoqIEpGl922vYm7fnMx0xojI7KSOU0o1U0rNTGV2k5OP7OY9XHPf9pJmebxctr0kItsttP2diLzruk0pVVEptdkqGy62NovIq6k47z95TMX5EeY1jl06pTY9pdQEpVSKy6FJORnOcYtIIPApMAHDyRYHvgJaWZB8CeAvpVSUBWnZxSWgtojkddn2IvCXVQbEwIlnpx1wB2gqIgUdsPf/kQ+UUtldlvnpnSFNMlBKZZgFyAXcAjokckwmDMd+3lw+BTKZ+xoCZ4EBQDBwAXjZ3DcWiAAiTRvdgTHAbJe0SwIK8DI/vwScAG4CJ4GuLtu3u5xXB9gLXDf/13HZtxkYB+ww01kH5EugbLH5/xroZW7zBM4Bo4DNLsd+BvwL3AD2A/XN7U/fV87fXPIx3sxHOFDG3PaquX8ysNgl/YnABkDScD83mjYPAANdtp8xr/Mtc6kN3Aaizc8hLvd6knl8kHldsiTjXvcwyx9hprfS3H4KaJKW5yiBcsZdx3j2LQQums/GVqBiEnksDCzG+AE/CfRJxO53wLtJbY8tj8vnIeYzdRP4E2hsbh/Dvd+HZ4E/gBCzjA+57DsFDAQOmWWbD2RObx/iLktGq3HXBjIDSxM5ZgRQC3gEqALUBEa67C+I8QNQBMM5/09E8iilRmPU4ucro2YyLbGMiEg24HOgmVIqB4Zz/jWe43yB1eaxeYGPgdX31Zi7AC8DBQAfjAc+MWYB3cz1p4DDGM7Flb0Y18AXmAMsFJHMSqm195Wziss5L2A4jBzA6fvSGwBUNkMW9TGu3YvK/JamFBEpgeEwfjCXbi67G5j/c5t53An0BHaan3Ob+98HyprlLINxT0e5pJPQvf7WtBlbG20ZTxZT9Ryl7CoAsAYIwLj3B8x8EV8ezbeglcBvpt3GQD8ReSoVduNFRMoBbwE1zOf6KQwnfP9xZYG5QD8gP/AjsFJEfFwO64hRUSgFPIxRodEkg4zmuPMCl1XioYyuwDtKqWCl1CWMmvQLLvsjzf2RSqkfMWoz5VKZnxigkohkUUpdUEr9Ec8xzwB/K6W+V0pFKaXmAscAV2cxQyn1l1IqHFiA4SwSRCn1C+Brfsm6YTjy+4+ZrZS6Ytr8CKMGmVQ5v1NK/WGeE3lfemEY1/FjYDbQWyl1Non0EuMF4JBS6ggwD6goIo8m92QREYwfmf5KqatKqZsYP0idXQ5Ly7125DlSSk1XSt1USt3BqNFWEZFcCRxeA8ivlHpHKRWhlDoBTOHeMt/PQBEJMZfLychSNMazUkFEvJVSp5RS/8RzXCdgtVJqvfmsTAKyYFRgYvlcKXVeKXUV4wfnkWTY15DxHPcVIJ9ro1U8FObe2uJpc1tcGvc5/jAge0ozopQKxXh4ewIXRGS1iJRPRn5i81TE5fPFVOTne4ya0RPE8wYiIgNF5KjZQyYEo3aYL4k0/01sp1JqN0ZoSDB+YOLF7J0R2xhWP4HDunG3dnkO2IIRq08u+YGswP5YxwSsNbfHkpZ7bftzJCKeIvK+iPwjIje4W7NN6D6VAAq7OOIQYDhGW09CTFJK5TaXpO4/SqnjGLXoMUCwiMwTkcLxHHrP9VFKxWA8P2l9rjVkPMe9E6Mxq3Uix5zHeMBjKc5/wwjJJRTDOcRyTwOaUuonpVRToBBGLXpKMvITm6dzqcxTLN8DbwI/mrXhOExnORjjVTWPGVq4juFwwYgfx0eiYQ8R6YVRGztvph9/IkbvjNjGsG3xpFMHIzwwTEQuishF4DGgi/mjHF8+7t92GSMWX9HFMeVSSiXXOSQV4rHyOUqILhiN6k0wflhLmtsTuk//AiddyptbKZVDKdU8hXaTeq7nKKXqYZRfYbRn3M8918d8AypG2p9rDRnMcSulrmPEMP8nIq1FJKuIeItIMxH5wDxsLjBSRPKLSD7z+CS7viXAr0ADESluvr4Oi90hIn4i0sqMdd/BeFWOiSeNH4GyZhdGL7M7VgVgVSrzBIBS6iTwOEYs9n5yAFEYDVheIjIKyOmyPwgomZKeI2ZM813geYyQwWAReSR1uedFYD3GdXjEXCphvGo3M/MdA/jfl+eisTFUs4Y3BfhERAqYeSySgnhv0H3p34+VzxEY9yGzy+KNcZ/uYLxJZsUI9SSWxz3ATREZIsaYA08RqSQiNVKYl1+B5iLia/bm6Re7Q0TKiUgjEcmE0SAcTvzP9QLgGRFpbJZlgFmWX1KYF008ZCjHDWDGawMxGoouYdRC3gKWmYe8C+zDaM3+HaPBJ1V9YZVS6zFaww9h9MxwdbYeZj7OA1cxnOgb8aRxBWiB8WBfwaiptlBKJSfemFT+tiul4qsF/oQRNvgL43X2NveGQWIHF10RkQNJ2TFrwbOBiUqp35RSf2O8on9vfsGTjYhkxngT+EIpddFlOYnxFvGi+QYxHthhhgRqYfRA+QO46BKrHQIcB3aZoYafSX6ceRpGHDdERJbFs9+y58hkMoYTjF1mYLRNnMaopR4BdiWWR6VUNMaz9AhGj5LLwFSM2npK+B6jgfMURi8m1y6CmTAafS9jhDoK4FJhiUUp9SfGj/gX5rEtgZZKqYgU5kUTD5LKRn+NRqPRpBMZrsat0Wg0GR3tuDUajcbN0I5bo9Fo3AztuDUajcbNSGygSroSGuFcq2lEVHy9mewhs7enY7aiY5y5hJ4ekvRBbkhktHPPhYc4cw09HKyq5W072TFb4SvfTPMFzPLoW8n+woQf/DJdH/oH1nFrNBqNozgy4aU1aMet0Wg0AA699ViBdtwajUYDusat0Wg0boeucWs0Go2b4eFcx4G0oh23RqPRgA6VOMGYt4ezbetmfH3zsnDpSgA++egDtm3ehJe3N8WKFWfMuAnkyJkziZSS5s6dO7zRvRsRERFER0fRqMmTvPZGbxbO+4H5c2Zx9t9/WbtxB7nzpEbgJHGio6Pp0qkdBQr48cVX31ia9thRw9m2xbiGC8xrGMv3M6fz6Ucf8POWneRxs3K50uzJRmTLlg0PDw+8PD2Zs2CJZWlfvHiBMSOGcvXqFQDatO/Ic1278fO6tXw7+UtOnTzBdz8soELFSmm2Fd+9+uarL1i6ZCF58vgC0KtPf+rVfzzNtly5eeMGY0eP5J/jfyMIo8eNp8ojydaziJdjU5/nZngk0TGKqOgY6gUuonLJvHzR63GyZfbmdPBNXp60npvhkVQPKMCXbzUEjEjG+Dl7WbHrpAUliwcdKrGflq3a0Om5rowaMTRuW63adejdNxAvLy8++3gS06d+S9/ApFS+ksbHx4cvv51O1qzZiIqMpMcrz1O7bgMefuRR6jZoyJuvpmR+/5QxZ/YsSvmXJvTWLcvTbvlsGzp27spol2sIhkPatXMHBQvFNz++NdhZrvuZMn1mnHOzEi9PT/oNHEz5hyoSGhpKt87teKxWHUqXCeCDT77gvXGjLbOV0L3q8vyLdHupu2V27ueD98dTp259Jn3yOZGREdwOv21Juk+PWM6VG3fTmtznCYZO/4Xth8/TrUl5+rd9lHd+2MMfZ65St/9ComMUBfNkZffnHVm955Q9YxTcqMbtPjm9j2rVa5Ar172zVdauUw8vL+O3qHKVKgQHXYzv1BQjImTNmg2AqKgooqKiQKBc+QoULlwkibNTT9DFi2zbupm27drbkn7VeK4hwMcfvEff/oNsq4DYXS6nyJe/AOUfqghAtmzZKOlfmkvBQZTyL03JkqUstZXQvbKTmzdvcmD/PtqY98nb28eSN9j4KFM4F9sPGzMQb/z1LK3rGNOMh9+JinPSmXw8sXVYnkjyl3TGthq3KdPVirtSReeAFUqpo3bZdGX50sU8+VRKhT8SJjo6mpe6tOfsv2do16kLlSpXSfqkNPLhxAn0CxxEaGio7bZi2bxpA/kL+FG2XHwqa9bgZLlE4I0e3RER2nXoRPsOnWyxc/7cOf48dpSKDjwXriyY9wOrVy6nQsVK9B84hJw5rXPu58+dJU8eX0aPHMZff/7JQxUqMnjocLJkzZr0yYmggJXvtEQpxbS1R5j+0xGOnrlGy1qlWLnrJG3rlqZovrtCRTXKFuDrvo0onj8H3T/+2b4Rwf/fa9wiMgRD4FUwVDn2mOtzRWRoIuf1EJF9IrJv+tRvU21/6rdf4+XpRfMW8Ylzpw5PT0++n7+UFT9t4sjh3/nn+N+WpR0fWzdvIo+vryXx0eQSHh7O9Cnf0LNXH9tsOF2uGbPmMm/hUv43eQoL5v7A/n17LbcRFhbKkAF9CBw0lOzZnZNNbN/pOZavXs/chcvIly8/n0yKT0Es9URFRXHs6BE6dHqOeYuWkiVLFqZPi099L2U0HryUOv0W0nrMal5/phJ1Kxbi9c830qN5JXZ80p7sWbzvmYZi71/BVOs1j3qBixjUoSqZ7Jo2wsMz+Us6Y1eNuzuG1t89SuAi8jGGSsn78Z2klPoW+BZSP1fJimVL2LZlE19P/Q6x4ZUmR46cVKtek12/bKN0mQDL04/l14MH2LJ5I9u3bSXizh1CQ28xfMhAJkycZJvNs/+e4fy5szzXoRUAwUFBdO3UlllzFpAvX/4kzk4eTpfLz8/QyfXNm5cnGjfl8O+HqFY9pUpeCRMVGcmQwL483bwljZo8aVm6ySFv3rvavm3adaDfW/8RWEoTfgULUsDPj8oPG28RTZ58ihlT0+64z1813rQuXQ9nxc6T1Cjrx6dLf6XlKKPRtUzhXDSrcb8MK/x59hq3wiOpWMKXA8cvpTkf/+H/e40bQ4MuvpatQsSvT2cJO7ZvY+aMaXz6xWSyZMliWbrXrl7l5s0bANy+fZs9u3+hRMnE5AjTTp/+A1i3YStr1m3k/Q8/pkbNWrY6bYCAsuX4ecsvrFq7kVVrN1LAz48f5i+xzGmDs+UKDwsjNPRW3PrOX3ZQJsC6H1ulFOPGjKSkvz9du71kWbrJ5dKl4Lj1TRt/prSFZQPIly8/BQsW4tTJEwDs2bUT/9Kl05Rm1kxeZM/iHbfe5NFi/HH6CvlzGd9XERjaqTpT1vwBQAm/HHGTmBXPn51yRfNwOvhmmvKQIB6S/CWdsavG3Q/YICJ/c1fLsDhQBkP/Mc0MGxzI/r17CQm5xtONH6dnr95Mn/otkRERvNHjFQAqP1yFEaPGptnW5cuXGDdqGNExMaiYGBo3fZp6DRoyf873zJ45natXLvN8x9bUrteAEaPHpdmeUwwfHMi+fcY1bNbkcV5/szet27p3g6ErV65cIbBvLwCioqNp1rwFdes1sCz93w4e4MdVKygTUJYuHdsA0Kt3PyIiIpj0/niuXbtK/7d6UrZceb74emqabMV3r/bv28Ofx44iIhQuXIThFjzr9zNk+EiGDxlEVGQkRYoVY+y4+/WKU0aB3FmZP+JpALw8PZi/5W/WH/iXXi0f5vVnjPDZ8p0nmPXzMQDqVCjEwPZViYyKIUYp+n699Z7eKJbiRjVu2zQnTYXwmtzbOLnXFDRNEj2ta9rR07qmDT2ta9pwu2ldG09I/rSuG4ZnzGldlVIx/FeVWqPRaB5MHoBGx+TitgNwNBqNxlLcKFTiPjnVaDQaO7FwAI6I5BaRRSJyTESOikhtEfEVkfUi8rf5P495rIjI5yJyXEQOiUjVpNLXjluj0WjAqHEnd0maz4C1SqnyQBXgKDAU2KCUCgA2mJ8BmgEB5tIDSLJxQDtujUajActq3CKSC2gATANQSkUopUIwRpLPNA+bCbQ211sBs5TBLiC3iBRKzIZ23BqNRgMpqnG7jvI2lx4uKZUCLgEzROSgiEwVkWyAn1LqgnnMRcDPXC/C3W7TAGe52xsvXh7Yxkknu5gVrtvXMVuXd3/hmC2nrqGTc+7EONdLFG9P5+o1Tl1DJ7s4Bi3s6ZgtS0hBrxLXUd7x4AVUBXorpXaLyGfcDYvEnq9EJNUPs65xazQaDVgZ4z4LnFVK7TY/L8Jw5EGxIRDzf+zQ13NAMZfzi5rbEkQ7bo1GowHLYtxKqYvAvyJSztzUGDgCrABiJ+9/EVhurq8Aupm9S2oB111CKvHywIZKNBqNxlGs7cfdG/hBRHyAE8DLGBXlBSLSHTgNdDSP/RFoDhwHwsxjE0U7bo1GowFLGxqUUr8C1ePZ1TieYxXQKyXpa8et0Wg04FYjJ7Xj1mg0GkCcnIErjWQYx71j21Ymvj+emOgY2rTrQPfXeiR9UhLkyp6FyaO7UKF0IZSCnmN/YPehk7zR+XFe71if6BjF2m2HGfHZ8rhzihXMw4HFIxn/9Y98+v2GFNuMT71+/U9r+Wbyl5w88Q/fz11AhYqV01y2+7lz5w6vvNiVyIgIoqKjadL0Kd58yx4lnFEjh7HVVCxfsnyVLTZisUOlPD6cvH4XL1xgxLDBXL1yBURo36EjXV+wTrB67KgRbN+ymTy+vnGK8sMG9ef0qVMA3Lx5gxw5cjJn4dI02bl48QJjRgzl6tUrALRp35Hnunbjs48/ZNuWTXh7e1O0aDFGvTPBNq1LV+wQXrEL26Z1TSu3o0h2xqKjo3n2maf4ZsoM/Pz86NKpPe9/+DGly5RJ1vl5asQ/RfiUd15gx8HjfLd0J95enmTN7EOV8kUZ8upTtOn9NRGRUeTPk51L1+4qlc/5sDtKKfb+fjpex51UP+79+/aSNWtWRo0YGue4T5z4Bw8Rxr8zmv4DByfbcadkqlClFOHhYWTNmo3IyEhe7taFwUNH8HCVR5I8N6XPe2wZRwwbkmLHndJ+3G8PH8KjVavTtn2HOJXy5DoBwZnrBym7hpcuBXP50iUeqlCR0NBbdO7Qjk8//1+ynvfk9OM+4PIMxjpuVz6ZNJHs2bPzWs/Ew7JJ3arLl4K5fPkS5R+qSGhoKN06t+PDT78kOCiI6jUfw8vLiy8+MUQ2evcfmGhaOTOnfdBCtg4zkv1whS58OV29vPu8GyTC4d8PUaxYCYoWK4a3jw9PN3+GzZtSXtt1JWf2zNSrWprvlu4EIDIqmuu3wunRoT6TZqwnIjIK4B6n3bLhw5w6d4Uj/6ReXT4+9Xp//9KULGWv4k58SvZ21UCqVa9BTgcUy51UKXfy+uXPX4CHKsSqy2fH39+f4OAgy9KvWr0GOXPljnefUoqff1rLU82eSbOdfPkLUP6h2HJko6R/aS4FB1GrTl28vIxgQKWHqxBkYdkSQ0SSvaQ3GcJxBwcFUbBQwbjPBfz8CApK280uWTgvl6/d4tuxz7Nz7hC+GtWFrJl9KFOiAHUfLc3WWQNZN7Uv1SoUByBbFh8GvNyU8d/8mCa76Ul0dDQd27WiUYM61KpdJ05r0F1xVSnv3L4NY0eNJDwszDZ76XH9zp07y7GjRx27Vwf378M3b16Klyhpabrnz53jz2NHqVj53nKsWLaEOnXrW2orIbTjTgQRSbCPouv4/2lTUq/ybgVeXp48Ur4YUxZuo/ZzEwkLv8PAV5ri5emBb65sNOg2ieGfLGP2B4ZM2siez/DF7I2Ehkeka77TgqenJwsWL+enDVs4/Pshjv/9V3pnKU3YpVKeEE5fv7DQUAb068OgocMdU5f/ac1qS2rbroSFhTJkQB8CBw29pxzTp3yNl6cnzZ5paam9hPDw8Ej2kt6kR+PkWGBGfDtcx/+nJMZdwM+PixfuhieCg4Li1L1Ty7mga5wLDmHv4dMALP35Vwa83JRzQSEs2/ArAPv+OE1MjCJfnuzUqFSCNk0eYXy/1uTKkYWYGMXtiEi+nr81TflID3LmzEmNmo+xY/s2ygSUTe/spBq7VMqTwonrFxkZSWC/PjR/piVNmjqjLh8VFcWmDT/z/bxF1qUZGcmQwL483bwljZrcLcfK5UvZvnUzX307w7kabvpXpJONLY5bRA4ltIu7M2JZRsVKlTlz5hRnz/6LXwE/1v64mvc+/ChNaQZducnZi9cIKFGAv08H07BmOY6duMiJs5d5vEZZtu77mzLFC+Dj7cXla7do0v3TuHNHvN6c0LA7buW0r169ipeXFzlz5uT27dvs2vkLL7/yWnpnK024qpSXLOVviUp5Qjh5/ZRSjBk1An9/f7q9lOQgO8vYs2snJUuVwq9gwaQPTgZKKcaNGUlJf3+6dnspbvsvO7bx/XfT+GbaLDJnyWKJreTwIIRAkotdNW4/4Cng2n3bBfjFamNeXl4MGzGKN3q8SkxMNK3btKNMmYA0pxs4cSEzJryEj5cnp85dpsfo2YSGR/DNmK7sWziciMhoXh31vQUluEt86vU5c+Xigwnvcu3aVfq82ZOy5cvz1TfTLLV7+VIwb48YSkx0NDFK8eRTT9Og4ROW2ohlyMBA9u3dQ0jINZo2asAbvXrTtl0He2xZrFKeEE5ev4MH9rNqxXICypalY9tWAPTuF0j9Bo9bkv7wwQPYv28PISEhNG/SkB5vvkXrtu1Zt/ZHnrQwTPLbwQP8uGoFZQLK0qVjGwB69e7HpIkTiIiIoFfP7gBUrlyFYW+PscxuQriT47alO6CITANmKKW2x7NvjlKqS1JppCRUklYS6g5oB05O6+qUcnhGndY1Jd0B02wrA07r6mRPYyu6A/q+MCfZOb76fZeMp/KulOqeyL4knbZGo9E4jTvVuDPMyEmNRqNJC+KgeEta0Y5bo9Fo0DVujUajcTu049ZoNBp3w338tnbcGo1GA7rG7XYE7/rcMVtFX5njmK0L33V1xM7N21GO2AFnK0VZfZKv+p12nCnZnUjnugNm8k7/oeEpQTtujUajcTMehDlIkot23BqNRgM6xq3RaDTuhg6VaDQajZuhHbdGo9G4GdpxazQajZuhh7w7THqoXv957CjvjRtDREQEnp6eDBkxikqVH05V+r990opbt6OIjokhKlrRaNRahrStTLeGZbhy8zYA4xb8xvrfzsedUzRvVnZObMHEJb/z5Y9H01zGHdu2MvH98cREx9CmXQe6v9YjzWneT3R0NK++0JH8+f344LOvGDtiMMeO/oGXlxcPVazM4OGj8fL2TpONO3fu0Ou1bnFq6080fpJXe77F/j27+PLTSURGRVKufAWGjRoXp2uYWsa8PZytWw21+kXmc3H9eghDBgZy/vw5ChcuwgeTPrFFXzM6OpoundpRoIAfX3z1jS3pdzfv1YeffcWi+T+wYM73nDv7L6t/3k7uPHnSbCO+7xXAvDmzWThvDp6eHtSt/zh9Awel2VZysLLGLSKngJtANBCllKouIr7AfKAkcAroqJS6Jobhz4DmQBjwklLqQGLpu0//l0Tw9PJk4OChLF35I7Pnzmfe3Dn8c/y4Zem3fLY1X0y+V0rt808m8VrPXsxZuJTXe/Xmc1ONOtU2xv9MgxFraDRqbdy2yWuP0WDEGhqMWHOP0wZ4t2s1fr5vW2qJjo5mwvh3+OrrqSxdsZq1P66y9PrFsnDu95QoeVf0+MlmLZizeBWz5i/jzp3brFy2OM02fHx8+Pzr6cyct5SZcxaz+5ft/P7bQd4dM4Kx701i9oLlFCxUmDWrlqfZVstWbfjf5HsVdWZMm0LNx2qxYvVP1HysFjNskkqbM3sWpfztEYUA416VdLlXD1epymeTp1GwUGHLbMT3vdq3ZzdbN21g7qJlLFi6ihdefMUye0lhg+bkE0qpR5RS1c3PQ4ENSqkAYIP5GaAZEGAuPYDJSSWcIRx3eqheiwihoYbC+62bt8ifv4Bl9pKiebWinLl0i2PnrluS3uHfD1GsWAmKFiuGt48PTzd/hs2bNliSdizBQRfZuX0rLVu3i9tWu16DuC9ChYqVLbln8amte3h44uXlHSdwW6NWHTZvXJ9mW9Wq1yDXfbXpzZs20LJVawBatmrNpk0/p9nO/QRdvMi2rZtpa6rXW01w0EV+ue9elS3/EIUKF7HUTnzfq0UL5vFi99fw8fEBwDdvXkttJoYDYsGtgJnm+kygtcv2WcpgF5BbRAollpBtjltEyotIYxHJft/2p+2yCc6pXg8YPIzPPp7EM02f4LOPP+Ctvv1TnZZSsGRoIzaNe5oXnygTt/21pmXZPqE5X7xWi1xZjQc5WyYv+raowMQlv6e5DLEEBwVRsNBdOaoCfn4EBVn3wwfw+Ufv80bfAUg8gxyiIiP5afVKatWpZ4mt6OhoXnyuLS2a1qdGrdpUqFSZ6Ogojh45DMDmn9cRfPFiEqmkjitXrsT9iOfLl58rV65YbuPDiRPoFzgIEXu+vp999D5vJnCv7ObM6VP8un8/L3bpRI+XX+CPw9Y950kiyV9chc3N5f7YogLWich+l31+SqkL5vpF7so4FgH+dTn3rLktQWy5MyLSB1gO9AYOi0grl90JakelVeXdSdXrRQvmEThoKKvXbyJw0FDGjR6Z6rSajVtHw5Fr6PDhJl5tUpY65Qow/ee/eTRwBfVH/EhQSDjvdq0KwJC2lZm89hihd5wbZp5WdmzdTO48vpR/qGK8+z96fxxVqlajyqPVLLHn6enJzLlLWLpmI0cO/87Jf47zznuT+PyjibzarRNZs2XFw9N+pyQilqvobN28iTy+vlSoWMnSdGPZsXUzeRK5V3YTFRXF9RvX+e6HefQJHMSwgf2xQ6UrPlJS41ZKfauUqu6y3O+w6imlqmKEQXqJSAPXncooVKoLZlfj5GtANaXULREpCSwSkZJKqc9IZHxSalXewXnV61UrljFwyHAAmjz5NO+OeTvVaV24Fg7A5Rt3WLX/X6qWzssvfwbH7Z+56TjzBzQEoHqZfLSqWZyxnR8lV1YfYpTiTmQ0U9b/lWr7Bfz8uHjhbg00OCgIPz/rNJ1//+0gO7ZuZteObURE3CH0VijvjBzCqHcnMv3brwi5do3xI8ZYZi+WHDlyUrV6TXb9sp0u3V5m8jRDH3T3zh38e/q05fYA8ubNy6VLweTPX4BLl4Lxzetrafq/HjzAls0b2b5tKxF37hAaeovhQwYyYWLa2lhiOfTbQbZv3cxOl3s1duQQRr870ZL0k8LPryCNGjdFRKhU+WHEw4OQa9fI42vtdYwPDwt7lSilzpn/g0VkKVATCBKRQkqpC2YoJPZLfg4o5nJ6UXNbwnm1LKf3pauUugWglDoFNASaicjH2DCwND1Ur/PnL8D+fXsB2Lt7F8WKl0hVOlkzeZI9s1fceqNKhTh6NgS/3JnjjmlRvRhHz4YA0Hzceqr0X06V/suZ/NMxPl7xR5qcNkDFSpU5c+YUZ8/+S2REBGt/XM3jTzRKU5qu9Ozdn6VrNrJo1XrGTJhEtRqPMerdiaxcuog9O3cwZsKHls0Tce3aVW7evAHAndu32bt7JyVKluLaVSNkERERwQ8zp9G6XUdL7N3P4w0bsXL5MgBWLl9GwycaW5p+n/4DWLdhK2vWbeT9Dz+mRs1aljltgDd692fZmo0sXrWesea9csppAzzeqDH79u4G4PSpk0RFRlrSgyU5WBXjFpFsIpIjdh14EjgMrABiu7u9iBGVwNzeTQxqAdddQirxYleNO0hEHlFK/Qpg1rxbANOBylYbSw/V65Gj32HSxAlER0fj45OJEaPfSVXa+XNmYXY/4y3K01NY/MspNhy6wNc961C5RB6UUpy5HEr/6bstKUt8eHl5MWzEKN7o8SoxMdG0btOOMmUCbLMXy6T33sGvYGFef9mQIX38iSa83OPNNKV55fIl3h09nJjoGGJUDI2aPEXdBg358tNJ/LJtCzEqhjbtO1GtZq0053/o4ED2791LSMg1nmr8OD179ebl7q8xZGB/li1dTKFChfngo0/SbOdBYOHc2fwwazpXr1ymW+c21K7bgGGjUvfMxxLf96pVm7a8M2okHdu0xNvbmzHvvufYwBgLzfgBS818ewFzlFJrRWQvsEBEugOngdjaw48YXQGPY3QHTLL2aZfKe1GMvov/aQESkbpKqR1JpeGkyruTytfFu891zJae1jVtODmtq1POycm2ESendc2RKe1xjnJDfkq2z/lz4lMZUuX9bCL7knTaGo1G4zRuNOI9Y4yc1Gg0mrRiZeOk3WjHrdFoNGjHrdFoNG6HDpVoNBqNm6GnddVoNBo3QztuC3BolCsAng7eMKe66AHcjox2xE72TM49Rk5+t2JinHsIQ8IiHLGTJ5uPI3YA8jQa45it8K1pt+VGfvvBddwajUbjJLpxUqPRaNwMHSrRaDQaN8ON/LZ23BqNRgO6xq3RaDRuhxv57YzjuJs92Yhs2bLh4eGBl6cncxYssSzt9BKFHTVyGFu3GHaXLF9ladpBFy8wZuQwrl69jCC0bteRzl1fAGDB3Nksmj8XDw9DrLV3/4GW2b1z5w6vvNg1Tsy3SdOnePOtPpal74rdItL3M2f2LJYsXohSirbtOlhuq1Orp8iaNSseHp54enry7az5/P3XMT5+fxwRd+7g6elJ/yEjeaiidRNw2vEM5sqemcmDn6VCqQIoFD3fX85TtQJoUa88MTGKSyGh9JiwjAtXbgLwUZ9mPFUrgLA7kfR4bxm//pXojKepRte404kp02eSJ4/1E663bNWGTs915e0RQ+O2xYrCvvJqD6ZP/ZYZ06bQN9A6BwfQqnVbnuvyPCOGDbE0XQBPTy/6DhhM+YcqEBoayovPtadmrdpcvXqFrZs3MnvBUnx8fLh61VrpLR8fH6ZMn0nWrNmIjIzk5W5dqFe/AQ9XecRSO3BXRPqhChUJDb1F5w7tqFW7LqXLlEn65BRy/O+/WLJ4Id/PWYC3tze9er5G/ccbUjyV87QnxCeTp5M79935qb/54mNeerUnj9Wpz64dW/n6i4/57OsZltmz4xmc1Odp1u0+TpdRC/D28iRrZm+OnLzEO9M2AfBmu8cY9tLj9PloFU/VCqB0UV8qdfmcmhWK8nngMzToOdWyvLjiTr1KMoRYsN2klyhsteo1LK/Fx5Ivf37KP1QBgGzZslHS359LwcEsWTCPbi+/eles1ddasdb4xHztqunYLSLtyskTJ6hU+WGyZMmCl5cX1arXYOPPaRckTgpBCA0NBSD01i3y5ctvafpWP4M5s2WiXpUSfLf6AACRUdFcv3Wbm2F34o7Jmtk7Tq6sRb1yzPnpNwD2HDlLruyZKZjXHllCkeQv6Y2dYsE1RaSGuV5BRAJFpLl99uCNHt15rmNbFi2cb5eZOJwQhXWK8+fO8dexo1Ss/LAh1npgP68834me3btxxAax1ujoaDq2a0WjBnWoVbuO7cLOYL+IdOmAAA4e2EdIyDXCw8PZvm0LFy9a+0ovCIN6v06Pbh1ZuXQhAG8FDuHrzz+iQ4smTP78I17r1c9Sm1ZTslAeLoeE8e2w1uyc+jpfDX6WrJm9ARjzaiP+XtSfzk0fZpxZ+y6cLydng2/EnX/u0g0K58tpS94cUHm3DLvEgkcDnwOTReQ94EsgGzBUREYkct5dseCpKRMLnjFrLvMWLuV/k6ewYO4PcbJiTmCHKKxThIWFMnRgX/oPGkb27NmJjo7mxo3rTPt+Hr37DWT44EDLxVo9PT1ZsHg5P23YwuHfD3H877RJryWFEyLS/v6leemV13izR3d69XyNcuUfwtPTWiGGL6bMZMr3C5j46WSWLZzHbwf2sXzxfHr1H8zCVT/Tq98gPnh3lKU2rcbL04NHAgoxZdlear/6DWG3IxjYtR4AY6ZuJKD9J8xbf4iebWs6njdd44b2QF2gAdALaK2UGgc8BXRK6CRX5eTur96vdp84seK2vnnz8kTjphz+/VBq854sYkVhAVtEYZ0gKjKSoQP68XTzFjzRuCkABfwK0tAUa61Y+WE8TLFWO8iZMyc1aj7Gju3bbEkfnBWRbtO2PXMWLGH6zNnkzJmTEiVKWpp+/gLGM57HNy/1Gjbm6JHD/LR6BQ2eaAJAwyZPcezIYUttWs25Szc4d+kGe48aWrhLNx/hkbKF7jlm/vrfaf24EcY7f/kGRQvcrWEXyZ+T85dvYAf/72vcGLJl0UqpMOAfpdQNAKVUOGC5Tlh4WBihobfi1nf+soMyAfZqJtotCms3SineHfs2JUv50+WFl+K2P/5EI/bv3QPAmdOniLRYrPXq1avcuGF88W7fvs2unb9QqpS/Zem74rSI9FUzXHbhwnk2/ryeZs1bWJZ2eHgYYWYsOzw8jH27f6FU6TLkzZ+fXw/sA+DA3t0ULVbcMpt2EHT1FmeDrxNQzGg7aVjNn2OnLlG66N2KT4t65fjrzGUAVm//ky5PGeGtmhWKciP0Dhev3LIlb+7kuO3qVRIhIllNx10tdqOI5MIGx33lyhUC+/YCICo6mmbNW1C3XgPL0k8vUdghAwPZt3cPISHXaNqoAW/06k3bdh0sSfu3Xw+wZtUKygSU5fmObQB4o3c/WrZuy7ujR/Jcu2fx9vZm9LgJlj6oly8F8/aIocRERxOjFE8+9TQNGj5hWfqu2C0ifT8DA/sQEhKCl5cXQ0eMIkdO62Kx165e4e1B/QCjjaDxU815rHY9smTJypcfv090VDQ+mTIxYNhoy2yCPc9g4GdrmPF2O3y8PTl1/ho93lvG5CHPElAsHzFKceZiCH0+Mroert31N0/VDuCPuX0IuxPJ6+8tTyL11ONOvUrsEgvOpJS6E8/2fEAhpVSSLV7hkc6JBdtxDRLCyYfDqdkBM3k5KarrmClHZwe8Hh7piJ0MPDtgmp+MJz77Jdk3fFPfOhlSLPg/Ttvcfhm4bIdNjUajSQsPQggkuWSoATgajUaTWtzIb2vHrdFoNAAebuS59chJjUajwWh/Su6SHETEU0QOisgq83MpEdktIsdFZL6I+JjbM5mfj5v7SyaVdoI1bhGpmtiJSqkDycq9RqPRuAE29BvoCxwFYrsXTQQ+UUrNE5Gvge7AZPP/NaVUGRHpbB6X4HgXSDxU8lEi+xTQKJmZ12g0mgceKxsnRaQo8AwwHggUI/FGQBfzkJnAGAzH3cpcB1gEfCkiohLp7pag41ZK2dO5Npk4GW5yUpg4JNSZbl8AubJ6O2LHt/XnjtgBODP/TcdsOSmC7GQ3Pae48rO1fcrtJiU+R0R6AK7Du79VSrnO0/EpMBjIYX7OC4QopaLMz2eBIuZ6EeBfAKVUlIhcN49PsAdekk+miGQFAoHiSqkeIhIAlFNKWTtBtEaj0aQjKZlvyHTS8U6oJCItgGCl1H4RaWhJ5u4jOVWKGcB+oI75+RywENCOW6PRZBgsjHHXBZ41Z0PNjBHj/gzILSJeZq27KIYvxfxfDDgrIl5ALiDR6UaT06uktFLqAyASwBzG7j79ZjQajSYZWNWrRCk1TClVVClVEugMbFRKdQU2YUzAB/AiEDt+f4X5GXP/xsTi25C8GneEiGTBaJBEREoD8Y6M1Gg0GnfFgX7cQ4B5IvIucBCYZm6fBnwvIseBqxjOPlGS47hHA2uBYiLyA8ZrwEupyLRGo9E8sNjht5VSm4HN5voJ4D8TjSulbgMpmrkrScetlFovIgeAWhghkr7mnCMajUaTYciIc5U8DtTDCJd4A0tty1EqsVMR/X7sV/N+kixZs+Hp4WGqeS9gzPAB/Hv6FAC3bt0ke/YcTPthsaV2o6Oj6dKpHQUK+PHFV9+kOb1j01/iZngE0TGKqOgY6vWbT+VS+fii1xNky+LN6aCbvPzhT9wMj8DL04PJfRrzSJn8eHl68MOGY0xauC9NZXn1hY7kz+/HB599xXvvvG2IDCgoVqIEw8eMj9O+tIKMql6/Y9tWJr4/npjoGNq060D311ImcJISZs/6jqVLFiEilAkIYOy498iUKZNt9u7Hjfx2sroDfgWUAeaam14XkSZKqV625iyF2KmI7opTat6f3qfmPWbC3fFQ//v0Q7LZIME1Z/YsSvmXJvSWdRPVPz1sCVdu3I77PLlPY4ZO2872w+fo1rQC/dtV5Z3Zu2hXrwyZvD2p0WsOWTJ5cXDy8yzY8idngm+myu7Cud9ToqR/nPhAn8Ahcdfsi48nsnj+HF54+bW0F9AkI6rXR0dHM2H8O3wzZQZ+fn506dSehk80stwOQHBQEHPnfM/iZavJnDkzgwf046c1q3m2dVvLbSWEpxt57uT0KmkEPKWUmqGUmgE05wEcNWmnIror6aXmHYtSik0/r6XJk9bqLgddvMi2rZtp26590gengTJFcrP9sNELauPBM7SuazgBhaHu7ekhZPHxIiIqmpthEamyERx0kZ3bt9Kydbu4bbFOWynFndt3LH8tzojq9Yd/P0SxYiUoWqwY3j4+PN38GTZv2mC5nViio6K5c+c2UVFR3L4dTv4CBWyzFR/upICTHMd9HHDVQypmbksRIjIrpec8iDih5g3CwN49eK1bR1aYat6xHDq4H1/fvBS1uIb/4cQJ9AschIh1844ppVg5rjU7PuvMK08bjubomau0rGVIlbWtF0DRfIZDXbL9OGG3Izk5+1X++u5lPl1ygGu3Utd56fOP3ueNvgMQj3vLMmHMCJ598nFOnzpB+05d01Cy+Mlo6vXBQUEULFQw7nMBPz+Cgqz/gYhNu9tLr9CsaSOaNqpP9uw5qF2nni22EsJDkr+kNwl+S0VkpYiswBiyeVRENovIJoxJU3IkdJ557or7lpVA29jPiZx3V+V9SspU3p3CCTXvL6fMYur3C/ng08ksWziX3w7cjfX+vO5HGj9lbW176+ZN5PH1pULFSpam23jwIur0nUfrUct5/ZmHqVuxMK9/+jM9nnmYHZ91JnsWbyKiDJWeGmX9iI6Jwf+FaTz0ynf0bVOVkgVTLv21Y+tmcufxpfxDFf+zb/iY8Sxbu4kSpfzZsH5tmst3PxlRvd4pbly/zuZNG1i19mfWbdhKeHg4q1cm6CpswZ1q3InFuCelId2iwBFgKsZbsADVSXziqnuGkd6Ock66LKW0adueNm2NkMIXn32Mn1/BJM5IGa5q3vUbNubokd+pUrU6UVFRbNv8M9/OXGCpvV8PHmDL5o1s37aViDt3CA29xfAhA5kwMS2PAJy/YsSXL10PZ8XOE9Qo58enSw7S8u1lAJQpnJtmNUoC0LFhOdbtP0NUdAyXroez88h5qpXx49TFlCl6//7bQXZs3cyuHduIiLhD6K1Q3hk5hFHvTgQM59rkqebMmTmdZ55tk6byJYSren2ZgLK22HBCvb6Anx8XL1yM+xwcFISfn58ttnbv2knhIkXx9TVEgxs1acpvvx3kmZbP2mIvPh4Af5xsEqxxK6W2JLYkkW51jGHyI4DrZl/G8GSe+8DjpJr33t2/UKq0oVi/f+8uipfwp4DFPxR9+g9g3YatrFm3kfc//JgaNWul2WlnzeRF9izecetNqhbnj9NXyZ8rC2B8SYZ2rsGUNYcBOHvpJg2rFI07vmb5Qvx59mqK7fbs3Z+lazayaNV6xkyYRLUaj/H2uPc5++9pwAjfbN+yieIlS6WpfPeTEdXrK1aqzJkzpzh79l8iIyJY++NqHn/CnuatgoUK8fuh3wgPD0cpxZ7dO227fgmRUWrcAIhILeAL4CHAB/AEQpVSCb7HKqVigE9EZKH5Pyg5ttKCnYro92O3mvfIQX0BI2baxFTzBti4bg2Nn2xmmS07KZAnK/NHPAOAl6cH87f8yfr9p+n1bBVeb/EwAMt/+YdZ648A8PWqQ3zbvwn7v+qKiPD9+iMcPpXodA3JRinF+NHDCb0VikJRJqAcA4eNsiTtWDKier2XlxfDRozijR6vEhMTTes27ShTJsBSG7FUfrgKTZo+SZeObfH08qJ8+Ydo1yHRKaktx/NBCF4nkyRV3kVkH8YQzIUYNeluQFml1LBkGxF5BqirlBqe3HOcDJU4qeZ9Izwq6YMsQk/rmjacnNb1AajEWY6T36usPmm/gq/M+z3ZGZ7euXK63rFkdSFQSh0HPJVS0WaXwKdTYkQptTolTluj0WicxkMk2Ut6k5wqRZipjfariHwAXEBrVWo0mgzGA+CPk01yHPAL5nFvAaEY/bidG86k0Wg0DpChGieVUqfN1dvAWAARmU8SYpYajUbjTjwA/jjZpLb1pbaludBoNJp0xp16lTjXbK7RaDQPMA9CCCS5JOi4RaRqQrswpnbNMDh5w7JltnZ4fGI4VazT895wxhBQvOEgx2xd3fmJY7acIonev9biPn4QcK8eF4nVuBMbnn7M6oxoNBpNepIhatxKKXuGfWk0Gs0DiBuFuHWMW6PRaEA3Tmo0Go3b4UZ+WztujUajAffqx51kQ6oYPC8io8zPxUXkPxLzGo1G485ktLlKvgJiMHQm3wFuAouBGjbmK8U4pUZtt5r32FEj2L5lM3l8fVmwdGXc9nlzZrNw3hw8PT2oW/9x+gZa2y3OiesXHR3Nay90Il+BAnzw6Vf0erUbYWHG3OPXrl7loYqVee+j1M00mCt7Zia/3ZkKpQuiFPR8Zy5Napfnlda1uHTNsDH6q9X8tOMoxQvl4deFQ/nr9CUA9hw+TZ/3FiaWfJI4qfI+auQwtm7ZjK9vXpYsX2WLDXC2TAA3b9xg7OiR/HP8bwRh9LjxVHnkUdvs3Y9V3QFFJDOwFciE4WMXKaVGi0gpYB6QF0Ov4AWlVISIZAJmAdWAK0AnpdSpxGwkx3E/ppSqKiIHAZRS18xJpx4YnFSjtlvNu+WzrenUuQujRgyN27Zvz262btrA3EXL8PHxiRNysAqnrt/CubMpUcqf0FBDRf5/U+/KkI4c1I96j6e+I9OkgW1Z98tRugz5Dm8vT7Jm9qZJ7fJ8MWcLn87e/J/jT5y7Qq2uaROLcMVJlfdWrdvyXJfnGTFsiOVpu+JkmQA+eH88derWZ9InnxMZGcHt8Nu22EkICyvSd4BGSqlbIuINbBeRNUAg8IlSap6IfA10Byab/68ppcqISGdgIklMKZKcH5lIEfHEkCBDRPJj1MAfGJxUo7Zbzbtq9RrkzJX7nm2LFszjxe6v4eNj/F765s1rmT1w5voFB11k546ttHBRXo8l9NYt9u/bQ/2GjVOVds5sman3qD/fLd8NQGRUNNdvOf2ld07lvVr1GuTMlcuWtF1xskw3b97kwP59tGlnSAJ6e/tYKlCSHDw9JNlLYiiDW+ZHb3NRGFGLReb2mUBrc72V+Rlzf2NJ4kInx3F/DiwFCojIeGA7MCEZ58UhIvVEJFBEbBHHc1KNGpxX8z5z+hS/7t/Pi1060ePlF/jj8O+Wpu/E9fv8o4m82Scw3vjgts0bqFbjMbKlUvC2ZBFfLofc4tvRz7HzhwF8NbITWTMbP3I9O9Znz9xBfD2qM7lzZLl7TmFfdv4wgHXf9KLuI9ZIZKWHyrvdOFWm8+fOkiePL6NHDqNz+zaMHTWS8LAwW2wlhJUq7yLiKSK/AsHAeuAfIEQpFaukchYoYq4XAf4FMPdfxwinJJzXpDKglPoBGAy8hzEXd2ulVKIBQRHZ47L+GvAlhjL8aBEZmsh5D7zKOziv5h0VFcX1G9f57od59AkcxLCB/UlKuehBYsc2I2ZfLh7ldYCf162hSRqU6708PXmkXFGmLNpB7a4fERYewcCXGjNl0Q4qtH6Xx7pM4uLlG7zf35D5unj5BmVbvEPtrh8x5JPlfPfu8+TIlinV9mNx+rlwAqfKFBUVxbGjR+jQ6TnmLVpKlixZmD5tii22EiIljZOuvspc7mkUMkVnHsEQTq8JlLc0r0kdICLFgTBgJbACCDW3JYbrXCY9gKZKqbHAk0DXhE5SSn2rlKqulKqeksYxJ9WoXXFV87YTP7+CNGrcFBGhUuWHEQ8PQq5dsyx9u69frPJ6h5ZPMmbEIA7s3cM7bxvx2ZCQaxz943dq12uQ6vTPBYdwLvg6e/84A8DSDb/xSPmiBF+9RUyMQinF9KU7qV7ReGwjIqO5et2ozR08dpYT564QULxAGkt5F6eeCyexu0x+BQtSwM8vrkbf5MmnOHbkiC22EkIk+YurrzKXeGuaSqkQYBPGjKq5RSS2XbEocM5cP4ehc4C5PxdGI2WCJCdUshpYZf7fAJwA1iRxjoeI5BGRvBi6lpfMQoQClosuOqlG7aSadyyPN2rMvr1G/Pb0qZNERUaSO08ey9K3+/r1fKs/S37cwMKV6xgz/kOq1qjJqHETAdj88zrq1HucTJlSX+MNunKTs0EhBJTID0DDmgEcO3GRgnnvxkhbPfEwR/65AEC+3NnwMN93SxbJS5li+Th5Lm0NvunxXNiNk2XKly8/BQsW4tTJEwDs2bUT/9KlbbGVEFaFSkQkv4jkNtezAE2BoxgOvL152IvAcnN9hfkZc/9GlcQrdXKEFCrfl6mqQFKKrbkwursIoESkkFLqgohkx4Y5w5xUo7ZbzXv44AHs37eHkJAQmjdpSI8336JVm7a8M2okHdu0xNvbmzHvvmdpI5GT1+9+Nqxbw/MvvZrmdAI/XMyMcS/g4+3JqXNX6DF2Lh8NasvDZQujFJy+cJXe440IX72qpXn79WZERhn3sPd7i7h2I23xVCdV3ocMDGTf3j2EhFyjaaMGvNGrN23bdbDcjpNlAhgyfCTDhwwiKjKSIsWKMXZciprS0oxY55oKATPNTh0ewAKl1CoROQLME5F3gYPANPP4acD3InIcuIohzp54XlMTKxWR3+936Mk8Lyvgp5Q6mdSxTqq8OxkujopxrkOOt6czE1XeCI90xA5AiScGO2bLyWldnRrT4eSzrpz7CpPVO+1X8INN/yQ7w4OfKJ2uo3CSrHGLSKDLRw+gKnA+NcaUUmFAkk5bo9FonCZDTOvqQg6X9SiMWPdie7Kj0Wg06UOGmWTKjNHkUEoNdCg/Go1Gky64UYU7UekyL6VUlIjUdTJDGo1Gkx48CJNHJZfEatx7MOLZv4rICmAhEBq7Uym1xOa8aTQajWM41JZvCcmJcWfG6AzeCGO8vZj/tePWaDQZBg83UjdOzHEXMHuUHOauw47F9n4+bjSiO0U41UUPnLuGOTJ7J32QRVzb5VwXvTzNP3TM1t/z+zpiJ2/2B2pizwcKN4qUJOq4PYGEBsxkULeq0Wj+v5JRepVcUEq941hONBqNJh3JKI2T7lMKjUajSSNu5LcTddypm9Veo9Fo3JCkBBIeJBJ03Eqpq05mRKPRaNITN+oNmKzugBqNRpPhyWhzlbgN0dHRdOnUjgIF/Pjiq29ssZER1bxjafZkI7Jly4aHhwdenp7MWWBfV30n7pUd1y9XtkxMDnyKCiXzGWryH62lSL7sjHihLuWL56V+7+858Lch++abIzNz3m5FtXIFmb3uMP3/l3odz1s3bzBpwhhOnTAU0AeOfIeKlR9h6YIfWL54Hh4enjxWpwGv9w5MOrFk4uSzfurkCYYMvJv3c2f/5Y23+tD1hRcTOcta3MdtZzDHPWf2LEr5lyb01q2kD04lGVHN25Up02eSJ4+v7XacuFd2XL9JbzZi3d6TdBm3Am8vD7Jm8ibk1m06v7OML/veK6l6OzKad2Zup0LJfFQsmS9Ndr/8ZCI1atVlzHsfExkZyZ3b4Rzcv4dftm7i2+8X4+Pjw7WraRODuB8nn/WSpfyZv3gZYPyoP9XocZ5o3MRyO4nhTr1K3CmskyhBFy+ybetm2rZrn/TBaSAjqnk7jVP3yurrlzOrD/UqF+W7tYZYc2RUDNdD7/Dnv1f5++x/peTCbkfyyx/nuB2RNtGnW7du8vvB/TR/ti0A3t7eZM+Rk5VL5tO5W3d8fIxBNXl8E9WXTTFOPuuu7Nm1k6LFilG4cJGkD7YQScGS3thS4xaRx4CjSqkbpnTPUIx5T44AE5RS1622+eHECfQLHERoaGjSB6eR6OhonuvYln/PnKHTc10yhJo3GN2h3ujRHRGhXYdOtO/QyRY7Tt4rKylZMDeXQ8L5dmAzKvvn5+DfQQycvJGw2/YKSVw8f45cefLwwbiRnDj+FwHlKtArcAhnz5zm998OMP3rL/DJ5MPrvQdSvkIlS22nx7P+05ofebr5M7bbuR8PN+pVYleNezqGwDDAZxhSZhPNbTMSOukelfepyVd537p5E3l8falQ0dqHNiEyopo3wIxZc5m3cCn/mzyFBXN/YP++vZbbcPpeWYmXp/BIgB9TVv1K7TdnEXY7koGdatpuNzo6mr//PMqzbTvxzayFZM6ShXmzphEdHc3N69f5ctoPvP7WAMaNGEhqFK0Sw+lnPTIygi2bN9L0yadttRMfHilY0hu7YtweSqnY98PqSqmq5vp2Efk1oZNMpeRvAcIjkz+s/teDB9iyeSPbt20l4s4dQkNvMXzIQCZMnJTa/CcLV+XrMgFlbbXlBLHK7r558/JE46Yc/v0Q1arXsNRGet0rKzh3+RbnLt1k7zFDdHjptj8Z0Okx2+3mL+BH/vx+PFTpYQAaNGrKvFnTyF/Aj3pPNEFEKF+xMuIhXA+5Rm4b2iiceta3b9tG+YcqkDdf2toEUoM79Sqx68fjsIi8bK7/JiLVAUSkLGD5e2Wf/gNYt2Era9Zt5P0PP6ZGzVq2OYKMqOYNEB4WRmjorbj1nb/soEyA9YLBTt4rqwm6FsrZSzcJKJoHgIaPluDYGWsbBOPDN28+8vsV5N/Thurfwb27KVGqNHUbNOLX/XsA+PfMKaIiI8mVO49ldtPjWV/74+p0CZOAjnEDvAp8JiIjgcvAThH5F/jX3Oe2ZEQ1b4ArV64Q2LcXAFHR0TRr3oK69RrYYssp7Lh+gf/bwIyhLfDx8uTUxRB6TFrDs3UD+PjNxuTLlYUl77bj0D/BPDt8EQDHZvUgR1YffLw9aVkngBbDFqbK2fceMIwJo4cSGRlJoSJFGTxyHJmzZOXDd9+me5c2eHl5M2TUeEtrjU6rvIeHhbF75w5Gjh5rm43EcKcad6pU3pOduEhOoBTGD8RZpVRQcs9NSajEnXDy2ciIU+M6ef30tK5pw91U3pceupjsDLd5uOCDrfKeFpRSN4Df7LSh0Wg0VuA+9e0MNgBHo9FoUosbRUoeiJ4tGo1Gk+54IMleEkNEionIJhE5IiJ/iEhfc7uviKwXkb/N/3nM7SIin4vIcRE5JCJVEzWAdtwajUYDGDXu5C5JEAUMUEpVAGoBvUSkAsZAxA1KqQBgg/kZoBkQYC49gMlJGdCOW6PRaABJwV9iKKUuKKUOmOs3gaNAEaAVMNM8bCbQ2lxvBcxSBruA3CJSKDEb2nFrNBoN4CmS7MV1lLe59IgvTREpCTwK7Ab8lFIXzF0XAT9zvQhGV+lYzprbEuSBbZx0sqEgMirGMVveXk6qvDvTHcud+r+mhMurBjpmK1/ziY7YubpmaNIHWUR0tIP9Ub3T/gym5DF2HeWdcHqSHVgM9DPnbXI9X4lIqi+QrnFrNBoNlsa4ERFvDKf9g1IqdmL7oNgQiPk/2Nx+DijmcnpRc1uCaMet0Wg0WBfjFqNqPQ1jhtSPXXatAGKVIV4Elrts72b2LqkFXHcJqcTLAxsq0Wg0GiexcFbXusALwO8uk+oNB94HFohId+A00NHc9yPQHDiOMYPqyySBdtwajUaDdQo4SqntJDwQs3E8xyugV0psaMet0Wg0kGQI5EEiwzhuO4V1L168wOgRQ7l69QoCtGnfkee6duP69RCGDQ7kwvlzFCpchPc//IScOa2TynJSLHjO7FksWbwQpRRt23WwTaTVSQHaixcuMGLYYK5euQIitO/Q0dJyjXl7ONu2Gvdn4dKVAHzy0Qds27wJL29vihUrzphxE8iRM2eq0s+VLROTBzSjQsn8KKXoOelHiuTPwYhu9ShfPB/135rJgb8uAlDcLxe/Tn+Vv/69CsCeo+fp89lPlpTTLmHnsaNGsH3rZvL4+rJgiXH9/vrzGO+9O4awsDAKFy7CuPc+JHv27JbZTAw3EsDJOI2TrVq3ZfI3U21J28vTk/4DB7Nw6SpmzJ7PwnlzOPHPcb6bPoWaNWuzdOVP1KxZm++mTbHUrp1lcuX433+xZPFCvp+zgPmLlrF1y2bOnDlti61YAdoFS1Ywf9EyftmxjUO//WqLLU8vTwYOHsrSlT8ye+585s2dwz/Hj1uWfstWbfhy8r33vFbtOixYupIFS1ZQvERJpqdAyel+JvVqwrq9J3jklSnUfH06x85c4Y9Tl+k8Zinbf//3P8efOB9CrZ4zqNVzhmVOG+4KO1tNy1at+WLyvdfn3bFv81bfQOYvXkHDRk34/rtplttNCKsaJ50gwzhuO4V18+UvQPmHKgKQLVs2SvqXJjg4iC2bNtLi2VYAtHi2FZs3bbDUrlNiwSdPnKBS5YfJkiULXl5eVKteg40/r7fFlpMCtPnzF+ChCrH3LTv+/v4EByd7ZuEkqVa9Brnuuz+169TDy8t4ka1cpQrBQRdTlXbObJmoV7kY3605BLgIE5+5wt9nr6Yt4ynATmHnqtVqkDNn7nu2nT59iqrVDNWlx2rXYeMGe57D+LCyO6Dd2OK4RaSPiBRL+kj34/y5c/x57CiVKlfh6tUr5MtfAIC8+fJz9ar9aih2UDoggIMH9hESco3w8HC2b9vCxYuJ9kZKE9HR0XRs14pGDepQq3YdRwRoz507y7GjRx0Vdl6+dDF1UilGUbJgLi5fD+PbQc+w8+uX+SqwGVkzeyd5zs6vX2bdR12oW6loquzeT6yws4gzdbzSpcuwxawA/bzuJ4JsfA7vx50UcOy6G+OA3SKyTUTeFJH8yTnpHrHgKal/xbSLsLBQBg/ow4BBQ/8TdxN5MF6hUoO/f2leeuU13uzRnV49X6Nc+Yfw9PS0zZ7TArRhoaEM6NeHQUOHOxYvnfrt13h5etG8RctUne/l6cEjAQWZsvIAtXvOMISJO9dK8PiLV29RtutX1O45gyFfb+C74c+SI2vaRBPSQ9h51NjxLJw/l+c7tyMsLBRv78R/rKwkJUPe0xu7GidPANWAJkAnYKyI7AfmAkvMiVf+g+sw0ttRD5YCTlRkJIMD+/J085Y0avIkAL6+ebl8KZh8+Qtw+VIweXytF2l1ijZt29OmrfE6/MVnH+PnV9B2m04I0EZGRhLYrw/Nn2lJk6ZP2mLjflYsW8K2LZv4eup3qQ4Dnbt0815h4q3HGPBcwo47IjKaq5HRABz8O4gTF0IIKOob13iZGtJD2LlkKX/+940R1z596iTbt26xzdZ/SH9/nGzsqnErpVSMUmqdUqo7UBj4Cngaw6m7FUop3hkzklL+/jzf7aW47Y83bMSqFcbgp1UrlvP4E43SKYdp5+oVI8xz4cJ5Nv68nmbNW9hjx0EBWqUUY0aNwN/fn24vJTmmwRJ2bN/GzBnT+PSLyWTJkiXV6RjCxDcIKGpUBhpWLcmx0wmH4vLlyoKH2S2iZKFclCmSh5MXQlJtH9JH2Dn2OYyJiWHalK9p16GTrfZccafGSVs0J0XkoFLq0QT2ZVVKhSWVRkpr3K7CsL5586ZIGDapSaZ+PbCfV19+njIBZfHwMH7r3uzdj0qVH2bYoEAuXjxPoUKFee/DT8iVK3eiaaVkkqm0lAkgJib5l/CVF7sSEhKCl5cXAwYN5bFatZN9bkpqlX/9eew/ArSvv/FWCmwl+1AO7N/Hy926ElC2LB5mjLZ3v0DqN3g8WedHJ3H9hg0OZP/evcb98c1Lz169mT71WyIjIsiVOzcAlR+uwohRSYvfxjfJ1MOlC/BVYDN8vD05dSGEHh+upkGVEnz8VhPy5cpKSOgdDv0TxLNDF9C6fjnefrEekVExxCjFuzO38+Ou//agSe0kU3v37GbWd9NT1B0wKjrx79XwIQPYv28PISEh5PXNS4833iI8PIyF8+YA8ETjprzVNzBZz1eOzGnvzLfnxPVkf2Fq+udKV+9tl+Muq5RKU+DSyVBJRp0dMCWOOy04OTugk+HFpBy3lWTE2QGTctxWYoXj3psCx10jnR23LTHutDptjUajcZz0j4AkmwwzclKj0WjSglVzlTiBdtwajUaDW1W4tePWaDQawK08t3bcGo1Gg54dUKPRaNwONwpxa8cN8E9wqGO2cmR27pIX8U39AJCUEOFgd0ovB+fedLKx6tpaZ7rp1Z+42RE7AJsGJq+//IOCdtwajUbjZuhQiUaj0bgZusat0Wg0boYb+W3tuDUajQZwK8+tHbdGo9GgY9wajUbjdriTWHCGcdxWK6JPnjSWA7u3kzN3Hj6asgCA+d9NZt8vWxDxIFfuPLwxaAy++fLzx2/7+HDUAAoULAJAzXpP0P6F11Jld9nCH/hp5RKUUjzdsi2tOz7Ptk3r+GH61/x7+iSffDubsuUrprl897Nj21Ymvj+emOgY2rTrQPfXeliW9sWLFxgzYmictFub9h15rms3Pvv4Q7Zt2YS3tzdFixZj1DupV0RPiIyoXm/1sx6Lh8CsV6oRfDOCwAW/M7pFeR4tkYvQO4ZAw9iVx/gr6BYl8mZlVItylC+Yg8mbTzJ793+Fi5PD2FHD2WaWY8FSQ+X9m6++YOmSheTJY8xD3qtPf+rVd6hboRs57gwjFmy1IvrjT7Zk2IQv7tnWssMLfPjtPD74Zg5Va9Vn8ey7Ct8PVX6UD76ZwwffzEm10z514jg/rVzCJ9/O5n8zFrDnl22cP3uGEqXKMHL8x1SqUjVNZUqI6OhoJox/h6++nsrSFatZ++MqS9XQvTw96TdwMAuWrmLG7PksmjeHE/8c57FadZi3eAVzFy2neImSfDfNWrm6jKpeb/WzHkvnGkU5efneqfI/33CCrlP30XXqPv4KugXAjfBIPlp3PNUOO5aWz7bhi8lT/rO9y/MvMnfhMuYuXOac08ZaIQURmS4iwSJy2GWbr4isF5G/zf95zO0iIp+LyHEROSQiSX7RM4zjtloRvcLDVcme497aX9Zsd/UKb98Ot3we6n9Pn6BchcpkzpwFTy8vKj1SjR1bNlC8pD9Fi5e01JYrh38/RLFiJSharBjePj483fwZSxXr8+UvQPmHYtXWs1HSvzSXgoOoVadunCJ6pYerEGShAjtkXPV6q591gAI5MlGvTF6W/5q0OO+1sEiOXLhJVHTa5iuvWr0GuSwuR1qwWOX9OwzFL1eGAhuUUgHABvMzQDMgwFx6AJOTStwulXcfEekmIk3Mz11E5EsR6SUizql/2sC86f/jzS7PsH3jGjq+2DNu+19HfmfQ68/x3vA+/Hvqn1SlXaJUGQ7/doAb10O4fTucfbu2c9liZxYfwUFBFCx0V2OygJ8fQUH22D1/7hx/HjtKxcr3qq2vWLaEOnXrW2rr/4N6vVUENi3D5xv/4X7tiDcblmLOq9Xp36Q03p7OxBIWzPuBTu2eZeyo4dy4cd0Rm2CtyrtSaitw9b7NrYCZ5vpMoLXL9lnKYBeQW0QKJZa+XTXuGcAzQF8R+R7oAOwGagAJvuM96CrvAJ1f6cVXc1ZTr1Ez1i43Yt+lypTnfz+s5MNv5vJ0q45MGj0wVWkXL+lPh64vMzLwDd4e2Av/MuXw8MwwL0WEhYUyZEAfAgcNvUdtffqUr/Hy9KTZM6lTRE+IjK5ebxX1yuTlWlgExy7eumf7l5tP0P7rPbw4Yz85s3jzYu3ituelfafnWL56PXMXLiNfvvx8MskZZSAgRZ7b1VeZS3IahfyUUrE1h4uAn7leBHCNO501tyWIXY2TlZVSD4uIF3AOKKyUihaR2cBvCZ30IKu830/9xs14b0QfOr74+j0hlEcfq8e0LyZy43oIOZPQn4yPp1q04akWbQD47pvPyVfAL4kz0k4BPz8uXrirBh4cFISfn7V2oyIjGRLYl6ebt6RRk7tq6yuXL2X71s189e0MW0ILGVW93kqqFM1J/YB81Cmdl0xeHmTL5Mk7zz7EqBVHAYiMVqz87SLP1ypme17y5s0Xt96mXQf6vfWG7TZjScncNK6+KjUopZSIpNrH2VWd8xARHyAHkBWIDWRlAtw2VHLh7Jm49b2/bKZIsZIAhFy9TKx25/Fjh4mJiSFHztTF7kKuGW9XwUEX+GXrRho2aZa2TCeDipUqc+bMKc6e/ZfIiAjW/rjaUsV6pRTjxoykpL8/Xbu9FLf9lx3b+P67aXz02VdkToMiemJkRPV6q/nf5pO0+GInrf63i+FLj7D3VAijVhwlb3afuGMalsvHiUv2T8Z26VJw3PqmjT9TOiDAdpuxWBkqSYCg2BCI+T+2sOcA11/Foua2BLGrxj0NOAZ4AiOAhSJyAqgFzLPDoKsietNGDVKsiH4/n40fzpFD+7l5PYQ3nmtOh249OLhnB+fPnsZDPMjnV4jX+g4DYNfWDaxftRgPT098fDLRd8SEVNcex48cwI3r1/Hy8uLN/sPIniMnv2zdyORP3+d6yDXGDO6Nf5lyvPtxku0XycbLy4thI0bxRo9XiYmJpnWbdpQpY90X5reDB/hx1QrKBJSlS0fjbaJX735MmjiBiIgIevXsDkDlylUY9vYYy+wCDAzsE6deP3TEKMu7G8Zy+VLwf9TrGzR8whZbVj/rCTGu1UPkyeqNIPwVdIv31hihn7zZfJj5SjWyZfJEKehcsyidvtlDaER0itIfPjiQffv2EhJyjWZNHuf1N3uzf98e/jx2FBGhcOEiDB811vJyJYj9IfwVwIvA++b/5S7b3xKRecBjwHWXkEq82KLyDiAihQGUUudFJDfQBDijlNqTnPOdDJUcO3/TKVN6Wtc04uS0rhlRvT6jTuuaPVPar+CJS7eT7XP882dO1J6IzAUaAvmAIGA0sAxYABQHTgMdlVJXxXjQvsTohRIGvKyU2pdY+rZ5EaXUeZf1EGCRXbY0Go0mrVj546mUei6BXY3jOVYBvVKSfoYZOanRaDRpQU/rqtFoNG6GnmRKo9Fo3Axd49ZoNBo3w438tnbcGo1GA+5V47atO2BacbI74MWQ206ZokDOTI7ZcrI7m1M4WSQnvxrKocfdyTLla/aeY7bCNwxP85Nx9lpEsq9O0Tw+6frl0jVujUajQQspaDQajdvhTi+o2nFrNBoNujugRqPRuB/u47e149ZoNBpwK7+tHbdGo9GAjnGnC3YpX8eyZN73rFm5BBGhVOkABgx/h4/fG8Pfx/7A08uLchUq0Xfw23h5WTvdeEZTKXdSDf3ihQuMGDbYmJNbhPYdOrr99Yvl5o0bjB09kn+O/40gjB43niqPPGpJ2mPeHs62rcZ3aaGpvr7+p7V8M/lLTp74h+/nLqBCxcqpTj9XtkxMHvgMFUrmRylFz0mrKZIvByNerE/54vmo32sGB/4yhD28vTz4sn8zqpYtRIxSDPzferb9diYJC6nDnbrPZhhdLLuUrwEuXwpi2aI5fDl9Lt/OXkJ0TAybf15LoyebM3Xucr75fjERd+6wZuVSS+1mRJVyJ9XQPb08GTh4KEtX/sjsufOZN3eOper1rjhZLoAP3h9Pnbr1WbpyDfOXLMPfv7Rlabds1YYv71NfLx0QwKRPPqdqteppTn/SW01Zt/cfHnn5G2r2mMqx05f549QlOo9ezPZD9zrlV54xfoxqvDaVFoPn8n7PxrbVjB0QUrCMDOO47VC+diU6Opo7d+4QHRXFndvh5M2Xn5p16iMiiAjlHqpkubBvRlQpd1INPX/+AjxUIVZdPjv+/v4E2yS+7GS5bt68yYH9+2jTzpBk8/b2sVQgolo86uv+/qUpaYGiT85smahXuTjf/WgoGEZGxXA99A5/nrnC32fv19aF8iXysfmgUVm5FBLG9Vt3qFY2UR3dVGOxyrut2Oa4RcRfRAaKyGci8rGI9BQRe+RHbCZffj/aP/ciL7R9iudaNSFbthxUe6xO3P6oqEg2/LSK6o/VtdRuRlUpTw819HPnznLs6FFbbTlVrvPnzpInjy+jRw6jc/s2jB01kvCwMFtsWU3Jgrm4fD2Mbwe3YOfXr/DVgOZkzZxwePH3f4JoUScATw+hRMFcPFq2IEUL2ONGJAV/6Y0tjltE+gBfA5kxlN0zYWiq7RKRhomc90CqvN+8cYOd2zYxc+GPzFm+ntu3w9nw0904+heTJlCpSjUqP1LVUrsZVaXcaTX0sNBQBvTrw6Chw+9Rl7cap8oVFRXFsaNH6NDpOeYtWkqWLFmYPm1K0ic+AHh5evBIQEGmrDhA7Z7TCbsdycDOtRM8fuaa3zh36SY7Jr/Ch282ZdcfZ4mOsUu1S9e4XwOaKaXexZAsq6iUGoEhzfNJQicppb5VSlVXSlXv/lpy1O6d4eC+XRQsXITceXzx8vKm7uONOfK78ao3e/rXXA+5xut9Btpiu03b9sxZsITpM2eTM2dOSpQoaYsdV1xVyt3dTmRkJIH9+tD8mZY0afpk0idYgN3l8itYkAJ+fnE1+iZPPsWxI0dssWU15y7d5NylG+w9ZghkLd16jEcCCiZ4fHSMYvDkn6n1+jQ6jlpE7uyZ4w2pWIF23AaxPVYyAdkBlFJncEOV9wJ+BTl6+BC3b4ejlOLXfbspXqIUa1YsYd/uXxg29n08POy5lBlNpdxJNXSlFGNGjcDf359uL71si41YnCxXvnz5KViwEKdOngBgz66d+Je2rnHSToKuhXL20k0CivoC0PDRkhw7fTnB47Nk8ooLpTSqVpKo6JhEj08L7hQqsWV2QBHpC3QHdgP1gYlKqRkikh9YrJRqkFQaKZ0d0FX52jdv3hQpXydndsBZU79iy4af8PT0pEzZ8vQbOoZWTWrh51eILGajVN3HG/H8Kz0TTSelswO+8mLXOJXyAYOG8lithF8r7ycljWN//XnsPyrlr7/xVory6oSdlNR2Duzfx8vduhJQtiweYvyw9u4XSP0GyROxTclXI63lSunsgH8eO8rYUSOJioykSLFijB03IVmN88kp07DBgezfa6iv+/rmpWev3uTMlYsPJrzLtWtXyZEjJ2XLl+erb6Ylmk5CswM+XLoAXw14Bh9vT05duEaPD1bToEpxPu79JPlyZSUk9A6Hjgfx7NB5FPfLxcqJnYmJUZy/fJM3Jq3mTPCN/6RpxeyAN24nPwaTM3P6Tkllp8p7ReAh4LBS6lhKz9fTuqYdd+qXmlz0tK5ptKOndU2Qmylw3DnS2XHbqfL+B/CHXelrNBqNpbhRPSfDjJzUaDSatPAgxK6Ti3bcGo1Gg3sJKWSYkZMajUaTJiwc8y4iT4vInyJyXESGWp1V7bg1Go0G67oDiogn8D+gGVABeE5EKliZV+24NRqNBksH4NQEjiulTiilIoB5QCtLM6uUylAL0CMj2dG23MtWRixTRraVljwC+1yWHi772gNTXT6/AHxppf2MWON2aqy8k2PytS33sZURy5SRbaUK5TI9h7k4OrlSRnTcGo1Gk56cw5hUL5ai5jbL0I5bo9ForGUvECAipUTEB+gMrLDSQEbsx+3UK4uTr0balvvYyohlysi2LEcpFSUibwE/AZ7AdGWMJLcM2+Yq0Wg0Go096FCJRqPRuBnacWs0Go2bkWEct91DTF3sTBeRYBE5bJcNF1vFRGSTiBwRkT/Mec7tspVZRPaIyG+mrbF22TLteYrIQRFZlfTRabJzSkR+F5FfRWSfzbZyi8giETkmIkdFJPmTp6fMTjmzPLHLDRHpZ5Ot/ubzcFhE5opIZjvsmLb6mnb+sKs8GYb07shuUWd4T+AfwB/wAX4DKthkqwFQFWOecbvLVQioaq7nAP6ysVwCZDfXvTFEMGrZWLZAYA6wyuZreArIZ/e9Mm3NBF41132A3A7Y9AQuAiVsSLsIcBLIYn5eALxkUzkqAYeBrBidJn4Gyjhx39xxySg1bvuHmJoopbYC9oje/dfWBaXUAXP9JnAU48tkhy2llLplfvQ2F1tarkWkKPAMMNWO9NMDEcmF8aM+DUApFaGUCnHAdGPgH6XUaZvS9wKyiIgXhlM9b5Odh4DdSqkwpVQUsAVoa5MttyejOO4iwL8un89ik4NLL0SkJPAoRk3YLhueIvIrEAysV0rZZetTYDAQY1P6rihgnYjsFxE7R+SVAi4BM8wQ0FQRyWajvVg6A3PtSFgpdQ6YBJwBLgDXlVLr7LCFUduuLyJ5RSQr0Jx7B7FoXMgojjtDIyLZgcVAP6XUfwX3LEIpFa2UegRjpFdNEalktQ0RaQEEK6X2W512AtRTSlXFmKmtl4gkqXeaSrwwQmiTlVKPAqGAbW0tAObgjmeBhTalnwfjzbUUUBjIJiLP22FLKXUUmAisA9YCvwLRdtjKCGQUx237ENP0QkS8MZz2D0qpJU7YNF/xNwFP25B8XeBZETmFEdJqJCKzbbADxNUaUUoFA0sxwmp2cBY46/KWsgjDkdtJM+CAUirIpvSbACeVUpeUUpHAEqCOTbZQSk1TSlVThpj4NYw2HU08ZBTHbfsQ0/RADLXfacBRpdTHNtvKLyK5zfUsQFMgxSLPSaGUGqaUKqqUKolxnzYqpWypxYlINhHJEbsOPInxSm45SqmLwL8iUs7c1Bg4YoctF57DpjCJyRmglohkNZ/FxhjtLLYgIgXM/8Ux4ttz7LLl7mSIIe/KgSGmsYjIXKAhkE9EzgKjlVLT7LCFUTt9AfjdjD0DDFdK/WiDrULATHMSeA9ggVLK1q56DuAHLDXV7r2AOUqptTba6w38YFYeTgAv22XI/CFqCrxulw2l1G4RWQQcAKKAg9g7HH2xiOQFIoFeDjXuuiV6yLtGo9G4GRklVKLRaDT/b9COW6PRaNwM7bg1Go3GzdCOW6PRaNwM7bg1Go3GzdCOW5MgIhJtzj53WEQWmkORU5vWdyLS3lyfKiIVEjm2oYikeKCHORNgvuRuTyCNl0TkSyvsajR2oR23JjHClVKPKKUqARFAT9ed5sRDKUYp9apSKrHBKQ2xcYSeRuPuaMetSS7bgDJmbXibiKwAjpgTU30oIntF5JCIvA7GqE8R+VKMOdJ/BgrEJiQim0Wkurn+tIgcMOcB32BOptUT6G/W9uubozoXmzb2ikhd89y8IrLOnL95KsbUtMlCRGqKyE5zQqhfXEY8AhQz8/i3iIx2Oed5MeYs/1VEvjEHK2k0jpMhRk5q7MWsWTfDmPwHjDk4KimlTpoz7l1XStUQkUzADhFZhzGTYTmgAsYIxiPA9PvSzQ9MARqYafkqpa6KyNfALaXUJPO4OcAnSqnt5nDonzCmAR0NbFdKvSMizwDdU1CsY0B9c9RtE2AC0M7cVxNjfugwYK+IrMaYNKoTUFcpFSkiXwFdgVkpsKnRWIJ23JrEyOIy1H4bxrwpdYA9SqmT5vYngYdj49dALiAAY27quUqpaOC8iGyMJ/1awNbYtJRSCc1z3gSoYA5dB8hpzpjYAHPOZqXUahG5loKy5cIY4h+AMfWrt8u+9UqpKwAisgSohzHkuxqGIwfIgjH9rUbjONpxaxIj3JzmNQ7TaYW6bgJ6K6V+uu+45hbmwwNDjed2PHlJLeOATUqpNmZ4ZrPLvvvngVAY5ZyplBqWFqMajRXoGLcmrfwEvGFOP4uIlDUnQNoKdDJj4IWAJ+I5dxfQQERKmef6mttvYki1xbIOYwInzOMeMVe3Al3Mbc2APCnIdy7uTv370n37moqIrzlLYmtgB7ABaO8yg52viJRIgT2NxjK049aklakY8esDYggof4PxJrcU+NvcNwvYef+JSqlLQA9giYj8Bsw3d60E2sQ2TgJ9gOpm4+cR7vZuGYvh+P/ACJmcSSSfh0TkrLl8DHwAvCciB/nvm+cejDnQDwGLlVL7zF4wIzHUdA4B6zFmVNRoHEfPDqjRaDRuhq5xazQajZuhHbdGo9G4GdpxazQajZuhHbdGo9G4GdpxazQajZuhHbdGo9G4GdpxazQajZvxf9OJzHVwd5mkAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Attention based Late Fusion\n",
    "selected_channels = [4, 9]\n",
    "dataset_type = 'alphabet'\n",
    "X_GAMMA, Y_FINAL = process_band(X, Y, l_freq=GAMMA[0], h_freq=GAMMA[1])\n",
    "X_BETA, Y_FINAL = process_band(X, Y, l_freq=BETA[0], h_freq=BETA[1])\n",
    "attention_fusion_accuracy = train_Attention_LateFusion(\n",
    "    X_GAMMA, X_BETA, Y_FINAL, selected_channels=[4, 9], dataset_type='alphabet', num_classes=10, epochs=500, batch_size=128\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "31760676",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # multi-branch\n",
    "# selected_channels = [4,9]\n",
    "# dataset_type = 'alphabet'\n",
    "# channels  = 'two_channel'\n",
    "# X_GAMMA, Y_GAMMA = process_band(X, Y, l_freq=GAMMA[0], h_freq=GAMMA[1])\n",
    "# X_BETA, Y_BETA = process_band(X, Y, l_freq=BETA[0], h_freq=BETA[1])\n",
    "\n",
    "# model = train_multibranch(X_BETA, X_GAMMA, Y_GAMMA, num_classes=10, epochs=500, batch_size=128, selected_channels=selected_channels)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
